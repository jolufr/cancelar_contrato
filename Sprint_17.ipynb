{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90dcd53f-e229-4c41-9a1c-a9c324242350",
   "metadata": {},
   "source": [
    "# Codigo del proyecto\n",
    "\n",
    "## 1. Deficion del problema\r\n",
    "\r\n",
    "\r\n",
    "### - Objetivo: Predecir la probabilidad de cancelación que tienen los clientes.\r\n",
    "#### Métricas objetivo:\r\n",
    "- Métrica principal: AUC-ROC (Área bajo la curva de la curva ROC).\r\n",
    "- Métrica adicional: Exactitud.\r\n",
    "#### Criterios de evaluación:\r\n",
    "- AUC-ROC < 0.75: 0 SP.\r\n",
    "- 0.75 ≤ AUC-ROC < 0.81: 4 SP.\r\n",
    "- 0.81 ≤ AUC-ROC < 0.85: 4.5 SP.\r\n",
    "- 0.85 ≤ AUC-ROC < 0.87: 5 SP.\r\n",
    "- 0.87 ≤ AUC-ROC < 0.88: 5.5 SP.\r\n",
    "- AUC-ROC \n",
    "\n",
    "\n",
    "## 1.1 Carga de los datos≥ 0.88: 6 SP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271fab1c-4e64-4f43-bc48-655e5bd9aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias y modulos requeridos para el ejecucion del codigo\n",
    "\n",
    "# Librerias para manejo de dataframe y arreglos \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modulos para mejorar la salida de los datos en pantalla\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Modulos para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Librerias y modulos para ML\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, log_loss\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e57e47-84ae-4e2a-ba5b-7e507d83a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los conjuntos de datos para la realicion del proyecto\n",
    "\n",
    "# Lista para guardar el nombre de los dataframe\n",
    "name_df = []\n",
    "\n",
    "# Dataframe que tiene la informacion personal de los clientes\n",
    "df_personal = pd.read_csv('../Datasets/personal.csv')\n",
    "name_df.append('df_personal')\n",
    "\n",
    "# Dataframe que tiene la informacion de los contratos\n",
    "df_contract = pd.read_csv('../Datasets/contract.csv')\n",
    "name_df.append('df_contract')\n",
    "\n",
    "# Dataframe que tiene la informacion de los servicios de internet\n",
    "df_internet = pd.read_csv('../Datasets/internet.csv')\n",
    "name_df.append('df_internet')\n",
    "\n",
    "# Dataframe que tiene la informacion de los servicios telefonicos\n",
    "df_phone = pd.read_csv('../Datasets/phone.csv')\n",
    "name_df.append('df_phone')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4174e3-66e4-419b-be3b-68737296bb8f",
   "metadata": {},
   "source": [
    "Verificacion de la carga y estructura de los conjuntos de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f9868-e9dc-480d-8465-7a0083750204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar la informacion de los dataframe para validar que se hallan cargado satisfactoriamente y poder analizar su estructura\n",
    "\n",
    "# Recorrer la lista de nombre de los dataframe para ver su estructura\n",
    "for df_name in name_df:\n",
    "    print(f'Conjunto de datos con la informacion de {df_name}')\n",
    "    print('-' * 60)\n",
    "    # Acceder al dataframe por su nombre\n",
    "    dataframe = globals()[df_name]\n",
    "    display(dataframe.info())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb70d12-39ec-46ed-9faf-9ec81c7014ee",
   "metadata": {},
   "source": [
    "## 2. Entendimiento del Conjunto de Datos\r\n",
    "\r\n",
    "\r\n",
    "### Revisión inicial:\r\n",
    "- Analizar la columna EndDate para confirmar que los clientes con valor ***\"No\"*** están etiquetados como no cancelados.\r\n",
    "- Identificar el balance de clases (proporción de cancelados vs. no cancelados).\r\n",
    "#### Preguntas clave:\r\n",
    "- ¿Qué variables parecen correlacionarse más con la cancelación?\r\n",
    "\r\n",
    "- ¿Hay variables redundantes o irrelevantes que se puedan \n",
    "\n",
    "\n",
    "## 2.1 Revisicion inicial de los datosminar?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c65e07-f472-45df-a7fc-aa2210f10ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar los valores de las columna EndDate\n",
    "print('Valores unicos en la columna EndDate')\n",
    "display(df_contract['EndDate'].unique())\n",
    "print('-' * 70)\n",
    "\n",
    "# Se filtran los clientes activos\n",
    "active_customer = (df_contract['EndDate'] == 'No')\n",
    "total_active_customer = active_customer.sum()\n",
    "\n",
    "# Se hallan el total de clientes en el conjunto de datos\n",
    "total_customer = len(df_contract['EndDate'])\n",
    "\n",
    "# Se imprime el numero y participacion de clientes activos y los que cancelaro su contrato\n",
    "print(f'Total clientes activos: {total_active_customer} --> {total_active_customer / total_customer * 100:.2f}% ')\n",
    "print(f'Total clientes que cancelaron su contrato: {total_customer - total_active_customer} --> {(total_customer - total_active_customer) / total_customer * 100:.2f}%')                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcd142-0d71-4fb4-9e9a-3419a893bc0b",
   "metadata": {},
   "source": [
    "Al revisar las diferentes caracteristicas aportadas por los conjutos de datos, se considera relevante analizar la influencia de las siguientes columnas en las predicciones del modelo:\r\n",
    " \r\n",
    "    df_personal\r\n",
    "        - gender\r\n",
    "        - SeniorCitizen\r\n",
    " \r\n",
    "    df_contract\r\n",
    "        - PaymentMethod\r\n",
    "        - TotalCharges\r\n",
    "\r\n",
    "    df_internet\r\n",
    "        - TechSupport\r\n",
    " \r\n",
    "    df_phone\r\n",
    "        - MultipleLines\r\n",
    "\r\n",
    "***Analisis datos columna EndDate***\r\n",
    "\r\n",
    "- Valores unicos: los valores unicos no presentan inconsistencias o rangos no permitidos.\r\n",
    "- Balance de clases: el ***73.46%*** de los clientes tienen su contrato vigente y el ***26.54%*** lo han cancelado, esto hace que posiblemente de deba usar sobremuestreo en el conjunto de datos para poder llevar a cabo un entrenamiento sin sesgos.\r\n",
    "\r\n",
    "No se observan columnas con datos irrelevantes, sin embargo se deben hacer pruebas de incidencia en los resultados para poder determinar la relevancia de caracteristicas y asi depurar los datos para una mejor interpretacion p\n",
    "\n",
    "## 3. Preparacion de los datos\r\n",
    "<a id='preparacion_de_los_datos'></a>\r\n",
    "\r\n",
    "Durante la preparacion de los datos se llevaran a cabo las siguientes tareas:\r\n",
    "\r\n",
    "- Limpieza de datos.\r\n",
    "- Codificación y transformación.\r\n",
    "- Análisis exploratorio de datos (EDA).\n",
    "\n",
    "### 3.1 Limpieza de datos\n",
    "\n",
    "\n",
    "- Se pasan a minuscula los nombres de las columnas.\r\n",
    "- Se pasa a minuscula el contenido de las columnas de tipo object.\r\n",
    "- Se eliminan espacios en blanco al inicio y al final de cada dato.\r\n",
    "- Se buscan registros duplicados.\r\n",
    "- Se revisan valores ausentes.\r\n",
    "- Se revisan los valores minimo y maximo de cada columna.\r\n",
    "- Se revisan los valores unicos de cada columna.\r\n",
    "- Se revisan y cambian los tipos de datos segun sea necesario para tratar la informacion.   (EDA)\r\n",
    "or parte del modelo.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f17e6-c4e7-4e55-a89e-b4f05a39d6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pasar a minuscula todas las columnas de datos tipo object\n",
    "\n",
    "# Se recorre la lista de nombre de los dataframe\n",
    "for df_name in name_df:\n",
    "    # Acceder al dataframe por su nombre\n",
    "    dataframe = globals()[df_name]\n",
    "    dataframe.columns = dataframe.columns.str.lower() # Pasa a minuscula el nombre de las columnas del dataframe\n",
    "    for column in dataframe.columns: # Recorre las columnas del dataframe\n",
    "        if dataframe[column].dtype == 'object': # Valida que la columna sea de tipo object\n",
    "           dataframe[column] = dataframe[column].str.lower() # Pasa a minuscula todo el contenido de la columna\n",
    "           dataframe[column] = dataframe[column].str.strip() # Elimina espacios en blanco al inicio y al final de cada dato\n",
    "           \n",
    "# Se imprime una muestra aleatoria de cada conjunto de datos para validar que el cambio se halla efectuado satisfactoriamente\n",
    "for df_name in name_df:\n",
    "    # Acceder al dataframe por su nombre\n",
    "    dataframe = globals()[df_name]\n",
    "    print(f'Conjunto de datos {df_name}')\n",
    "    print('')\n",
    "    display(dataframe.head())\n",
    "    print('-' * 60)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf4551-c74b-42bd-a8b4-73687211d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los valores de yes a 1 y de no a 0 en las columnas partner, dependents paperlessbilling y multiplelines\n",
    "df_personal['partner'] = df_personal['partner'].map({'yes':'1', 'no':'0'})\n",
    "df_personal['dependents'] = df_personal['dependents'].map({'yes':'1', 'no':'0'})\n",
    "df_contract['paperlessbilling'] = df_contract['paperlessbilling'].map({'yes':'1', 'no':'0'})\n",
    "df_phone['multiplelines'] = df_phone['multiplelines'].map({'yes':'1', 'no':'0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726a067-7404-4295-bf58-ae0a5d0c4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar registros duplicados\n",
    "\n",
    "for df_name in name_df:\n",
    "    # Acceder al dataframe por su nombre\n",
    "    dataframe = globals()[df_name]\n",
    "    print(f'Conjunto de datos {df_name}')\n",
    "    duplicated_row = dataframe.duplicated().sum()\n",
    "    print(f'Numero de filas duplicadas: {duplicated_row}')\n",
    "    print('-' * 30)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fdf43-5ac2-4d52-aa3f-75cc525ceef8",
   "metadata": {},
   "source": [
    "No se hallan registros duplicados en los conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f2789-1bfa-478a-8a09-fc6fceeccd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar valores ausentes\n",
    "\n",
    "for df_name in name_df:\n",
    "    # Acceder al dataframe por su nombre\n",
    "    dataframe = globals()[df_name]\n",
    "    print(f'Conjunto de datos {df_name}')\n",
    "    for column in dataframe.columns: # Recorre las columnas del dataframe\n",
    "        print('Columna: ', column)\n",
    "        print('Total valores ausentes: ', dataframe[column].isna().sum())\n",
    "        total_isna = dataframe[column].isna().sum()\n",
    "        len_column_dataframe = len(dataframe[column])\n",
    "        print(f'Porcentaje valores ausentes: {total_isna / len_column_dataframe * 100:.2f}%')\n",
    "        print('-' * 30)\n",
    "\n",
    "    print('*' * 30)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec1dfc-c84a-48bb-b972-fd3c84f30b24",
   "metadata": {},
   "source": [
    "***Analisis valores ausentes***\r\n",
    "\r\n",
    "Solo se encontraron valores ausentes en dos de las columnas de los cuatros conjuntos de datos, este es el detalle los hallagos:\r\n",
    "\r\n",
    "- df_contratc\r\n",
    "\r\n",
    "    - columna enddate: tiene 5174 valores ausentes que representa el ***73.46%*** de los datos. Estos valores ausentes existen porque la columna hace referencia a la fecha de cancelacion del contrato y al estar vigente el contrato, no existe fecha de cancelacion.\r\n",
    "\r\n",
    "    - columna totalcharges: tienee 11 valores ausentes que representan el ***0.16%*** de los datos. Por ser tan poco representativa la cantidad de registros con valores ausentes, estos se van a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ec7ce-118d-447b-8189-728829d9edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar los valores ausentes en la columna totalcharges del conjunto de datos df_contract\n",
    "\n",
    "df_contract['totalcharges'] = df_contract['totalcharges'].dropna()\n",
    "\n",
    "print('valores ausentes en la columna totalcharges: ', df_contract['totalcharges'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f702f6-cd55-42be-bbc3-48fd59cdeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar los valores minimo y maximo de las columnas numericas\n",
    "\n",
    "for df_name in name_df:\n",
    "    # Acceder al dataframe por su nombre\n",
    "    dataframe = globals()[df_name]\n",
    "    print(f'Conjunto de datos {df_name}')\n",
    "    for column in dataframe.columns: # Recorre las columnas del dataframe\n",
    "        print('Columna: ', column)\n",
    "        print('Tipo de dato: ', dataframe[column].dtype)\n",
    "        min_value = dataframe[column].min()\n",
    "        max_value = dataframe[column].max()\n",
    "        print(f'Valor minimo: {min_value}')\n",
    "        print(f'Valor minimo: {max_value}')\n",
    "        print('-' * 30)\n",
    "\n",
    "    print('*' * 30)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ab2df-5cf1-4a9d-b545-fa569f9865f1",
   "metadata": {},
   "source": [
    "***Analisis valores maximo y minimo***\n",
    "\n",
    "Al revisar los valores minimo y maximo de todos los conjuntos de datos, se pueden observar las siguientes novedades:\n",
    "\n",
    "- Conjunto de datos df_personal:\n",
    "    - La columna seniorcitizen maneja valores de 0 y 1 con un tipo de dato object. Se pasara int para disminuir el consumo de memoria al almecenar el dato.\n",
    "\n",
    "- Conjunto de datos df_contract\n",
    "    - La columna begindate maneja fechas con un tipo de dato object. Se pasara a tipo datetime para procesar correctamente los datos de fecha.\n",
    "    - La columna enddate maneja fechas con un tipo de dato object. Se pasara a tipo datetime para procesar correctamente los datos de fecha.\n",
    "    - La columna totalcharges maneja datos numericos con un tipo de dato objetc. Se pasara a float64 para procesar correctamente los datos.\n",
    "\n",
    "Las demas columnas tiene un tipo de dato acorde a la informacion que representan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfb273-1693-4946-b8da-d91c5854ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar los valores unicos de cada columna\n",
    "\n",
    "for df_name in name_df:\n",
    "    # Acceder al dataframe por su nombre\n",
    "    dataframe = globals()[df_name]\n",
    "    print(f'Conjunto de datos {df_name}')\n",
    "    for column in dataframe.columns: # Recorre las columnas del dataframe\n",
    "        print('Columna: ', column)\n",
    "        print('Valores unicos: ', dataframe[column].unique())\n",
    "        print('-' * 30)\n",
    "\n",
    "    print('*' * 30)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52972ee4-4cf4-4067-b5d1-be85065fb80c",
   "metadata": {},
   "source": [
    "***Analisis valores unicos***\n",
    "\n",
    "Los valores unicos encontrados en las diferentes columnas estan dentro de los valores permitidos segun la informacion de representan, sin embargo, la columna begindate del conjunto de datos df_contract maneja fechas, estos datos estan estructurados como object; la columna de debe pasar a datetime para que las fechas se procesen adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7f759-9c7e-4225-89d4-81ee8457b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el tipo de dato en las columnas que se mencionan en el analisis de los valores minimo y maximo\n",
    "\n",
    "df_personal['seniorcitizen'] = df_personal['seniorcitizen'].astype('int64')\n",
    "df_contract['begindate'] = pd.to_datetime(df_contract['begindate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89003ba-04d2-464c-ac15-b7e952b3f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar los datos de la columna totalcharges para saber si todos se pueden convertir a tipo float\n",
    "\n",
    "# Se reemplaznr valores no numéricos con NaN temporalmente\n",
    "non_numeric = pd.to_numeric(df_contract['totalcharges'], errors='coerce').isna()\n",
    "\n",
    "# Se cuentan filas con valores no numéricos\n",
    "non_numeric_count = non_numeric.sum()\n",
    "\n",
    "print(f\"Filas con valores no numéricos: {non_numeric_count}\")\n",
    "\n",
    "# Eliminar filas con valores no numéricos en 'totalcharges'\n",
    "df_contract = df_contract[~non_numeric]\n",
    "\n",
    "df_contract['totalcharges'] = df_contract['totalcharges'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050cdbe5-e433-47f0-b70e-c69f8708fa02",
   "metadata": {},
   "source": [
    "Al encontrar solo 11 filas con valores no numericos en la columna totalcharger, estos registros se eliminan.\r\n",
    "\r\n",
    "Se procede a verificar que los cambios de tipo de dato se hallan efectuado satisfactoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99486f92-35c6-48d7-8342-fcd71d6a364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir 5 filas aleatorias y los valores unicos para cada columna\n",
    "\n",
    "print('Conjunto de datos df_personal')\n",
    "display(df_personal['seniorcitizen'].sample(5))\n",
    "print('Valores unicos', df_personal['seniorcitizen'].unique())\n",
    "print('-' * 60)\n",
    "print('')\n",
    "\n",
    "print('Conjunto de datos df_contract')\n",
    "display(df_contract['begindate'].sample(5))\n",
    "print('Valores unicos', df_contract['begindate'].unique())\n",
    "print('-' * 60)\n",
    "print('')\n",
    "\n",
    "print('Conjunto de datos df_contract')\n",
    "display(df_contract['enddate'].sample(5))\n",
    "print('Valores unicos', df_contract['enddate'].unique())\n",
    "print('-' * 60)\n",
    "print('')\n",
    "\n",
    "print('Conjunto de datos df_contract')\n",
    "display(df_contract['totalcharges'].sample(5))\n",
    "print('Valores unicos', df_contract['totalcharges'].unique())\n",
    "print('-' * 60)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf5451-067a-411c-8234-4a3e4c969da2",
   "metadata": {},
   "source": [
    "### 3.1.1 Codificación y transformación\r\n",
    "\r\n",
    "Se realizaran las siguientes tareas:\r\n",
    "\r\n",
    "    - Consolidar los datos en un único registro por cliente.\r\n",
    "        - Revisar valores ausentes en el nuevo conjunto de datos.\r\n",
    "    - Codificar variables categóricas, como métodos de pago y tipos de contrato, utilizando técnicas como One-Hot Encoding.\r\n",
    "    - Escalar variables numéricas para modelos sensibles a la escala.\r\n",
    "    - Crear nuevas características útiles, como duración del contrato en días o número total de servicios cont\n",
    "\n",
    "\n",
    "***Funcion para unir los conjuntos de datos***ratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afabdc-be34-4b3f-b35a-e4da24f1de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un unico conjunto de datos con un registro por cliente\n",
    "\n",
    "df_consolidated = pd.DataFrame()\n",
    "\n",
    "def join_df(df_left, df_right):\n",
    "    \"\"\"\n",
    "    La funcion join_df une dos dataframe conservando los registros del dataframe de la izquierda y usando como clave la columna customerid\n",
    "\n",
    "    Parametros\n",
    "    df_left: pasa el dataframe que se usara a la izquierda de la union.\n",
    "    df_right: pasa el dataframe que se usara a la izquierda de la union.\n",
    "\n",
    "    Retorno\n",
    "    El retorno de la funcion en en nuevo dataframe con el mismo numero de filas del conjunto de datos de la izquierda y la suma de las columnas de los\n",
    "    dos conjuntos de datos menos una, que es la que se usa como clave de la union.\n",
    "    \n",
    "    \"\"\"\n",
    "    total_columns_left = df_left.shape[1]\n",
    "    total_columns_right = df_right.shape[1]\n",
    "    \n",
    "    total_columns_consolidated = total_columns_left + total_columns_right - 1\n",
    "    total_rows_left = len(df_left)\n",
    "    \n",
    "    print('Numero de columnas del conjunto de datos de la izquierda: ', total_columns_left)\n",
    "    print('Numero de filas del conjunto de datos de la izquierda', len(df_left))\n",
    "    print('')\n",
    "    print('Numero de columnas del conjunto de datos de la derecha: ', total_columns_right)\n",
    "    print('Numero de filas del conjunto de datos de la derecha', len(df_right)) \n",
    "    print('')\n",
    "    df_join = pd.merge(df_left, df_right, on='customerid', how='left')\n",
    "    print('Numero de columnas del nuevo conjunto de datos: ', total_columns_consolidated)\n",
    "    print('Numero de filas del conjunto de datos de la derecha', len(df_join))\n",
    "    print('')\n",
    "\n",
    "    return df_join, total_columns_consolidated, total_rows_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44829ae7-310f-4414-81e6-45beae46f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion validar el tamaño de la fusion\n",
    "\n",
    "def validation():\n",
    "    \"\"\"\n",
    "    La funcion valida el tamaño del nuevo conjunto de datos al comparar el numero de filas y columnas resultantes con los datos \n",
    "    generados antes de la fusion\n",
    "\n",
    "    Parametros\n",
    "    La funcion no utiliza parametros\n",
    "\n",
    "    Retorno\n",
    "    La funcion no genera un retorno, unicamente muestra en pantalla si el nuevo conjunto de datos cumple o no con el numero de filas y columnas esperados\n",
    "    \"\"\"\n",
    "    print('Validacion de la fusion')\n",
    "    print('-' * 80)\n",
    "    \n",
    "    columns = df_consolidated.shape[1]\n",
    "    rows = len(df_consolidated)\n",
    "    \n",
    "    if columns_validation ==  columns and rows == rows_validation: \n",
    "        print('El nuevo conjunto de datos cumple con el numero de filas y columnas esperados')\n",
    "        print('-' * 80)\n",
    "        print('Numero de columnas del nuevo conjunto de datos: ', df_consolidated.shape[1])\n",
    "        print('Numero de filas del nuevo conjunto de datos: ',len(df_consolidated))\n",
    "    else:\n",
    "        print('El nuevo conjunto de datos no cumple con el numero de filas y columnas esperados')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6135c-cfd2-469d-aa61-a9f9de9c69ab",
   "metadata": {},
   "source": [
    "***Union de los conjuntos de datos df_personal y contract***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1775005-ca54-4539-8a13-7eeabe788b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la funcion\n",
    "df_consolidated, columns_validation, rows_validation = join_df(df_personal, df_contract)\n",
    "\n",
    "validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312fbe2-e90d-420c-8547-cb33f01b5df1",
   "metadata": {},
   "source": [
    "***Union de los conjuntos de datos df_consolidated y df_internet***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff39df6-e1bc-41a1-9261-09fbb8569ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamar a la funcion\n",
    "df_consolidated, columns_validation, rows_validation = join_df(df_consolidated, df_internet)\n",
    "\n",
    "validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79895d4f-11cc-4f25-aa88-263528f48924",
   "metadata": {},
   "source": [
    "***Union de los conjuntos de datos df_consolidated y df_phone***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bdb95-f011-4dd8-8d87-aa8b3daeb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la funcion\n",
    "df_consolidated, columns_validation, rows_validation = join_df(df_consolidated, df_phone)\n",
    "\n",
    "validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d69cb-c98c-45bb-93ba-b809d4e021c2",
   "metadata": {},
   "source": [
    "Revisar valores ausente en el nuevo conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6cd2b-5aa1-4545-ab04-eba5aae1c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_consolidated.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66df01-af42-4411-ab6e-84760b5d9df9",
   "metadata": {},
   "source": [
    "Se procede a validar el tamaño de los conjunto de datos para hallar las diferencias de filas con el conjunto de datos df_personal y validar si los valores ausentes en el nuevo conjunto de datos df_consolidated corresponden a esta diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f34e5-be87-47ee-a3b2-c05fbc8e2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df_personal = len(df_personal)\n",
    "len_df_contract = len(df_contract)\n",
    "len_df_internet = len(df_internet)\n",
    "len_df_phone = len(df_phone)\n",
    "\n",
    "print('Numero de filas del conjunto de datos de df_personal: ', len_df_personal)\n",
    "print('Numero de filas de diferencia del conjunto de datos df_personal y de df_contract: ', len_df_personal - len_df_contract)\n",
    "print('Numero de filas de diferencia del conjunto de datos df_personal y de df_internet: ', len_df_personal - len_df_internet)\n",
    "print('Numero de filas de diferencia del conjunto de datos df_personal y de df_phone: ', len_df_personal - len_df_phone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d1a11c-c2ac-404b-987b-6388943c36b8",
   "metadata": {},
   "source": [
    "La validacion confirma que los valores ausentes en el nuevo conjunto de datos df_consolidated corresponden a las diferencias del numero de filas. \r\n",
    "Conociendo esto, se procede a reemplazar los valores ausentes\n",
    "\n",
    "Se obtienen los nombres de las columnas que tiene valores ausentes en el nuevo conjunto de datos df_consolidated.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e52733-a81d-4456-ab92-b8f0b322f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear lista para guardar el nombre de las columnas con valores ausentes\n",
    "name_columns_na = []\n",
    "\n",
    "# Se recorren todas las columnas de dataframe\n",
    "for column in df_consolidated.columns:\n",
    "    values_na = df_consolidated[column].isnull().sum()\n",
    "    if values_na > 0:\n",
    "        name_columns_na.append(column)\n",
    "\n",
    "display(name_columns_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95492e4f-a111-4982-8e4a-bb6588011444",
   "metadata": {},
   "source": [
    "Se gerenan los valores unicos de las columnas con valores ausentes para determinar con que valor se pueden reemplazar estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c3fb9-f285-4034-94a5-82c7eb2566d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in range(len(name_columns_na)):\n",
    "    column_na = name_columns_na[column]\n",
    "    print('Valores unicos en la columna ', column_na)\n",
    "    display(df_consolidated[column_na].unique())\n",
    "    print('-' * 80)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123be0e4-a77a-4bb9-bf6f-4e98f705f4e3",
   "metadata": {},
   "source": [
    "Para tratar as columnas con valores ausentes, se procesaran primero las que menos datos tengan por reemplazar para asi tener una estructura mas completa al momento de abordar las columnas con mayor cantidad de datos a ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a2459-871d-4a2b-a421-368e76ba5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_validated(df_a, df_b, column_validated):\n",
    "    \"\"\"\n",
    "    La funcion recibe tres parametros, los dos primeros son dataframe, y con ellos se busca que elementos del primer conjunto de datos no\n",
    "    se encuentra en el segundo. El tercer parametro es la columna que se usara para hacer la busqueda\n",
    "\n",
    "    Parametros\n",
    "    df_a: es el dataframe que se usa para selecionar los elementos a buscar en el segundo dataframe\n",
    "    df_b: es el dataframe en el cual se hace la busqueda de los valores.\n",
    "    column_validated: es el nombre de la columna que se usara para poder hacer la busqueda\n",
    "\n",
    "    Retorno\n",
    "    La funcion no retorna valores, pero genera impresiones que indican los resultados obtenidos\n",
    "    \"\"\"\n",
    "    # Se crean conjuntos con los datos de la columna customer_id de los dataframe df_personal y df_contract\n",
    "    set_a = set(df_a[column_validated])\n",
    "    set_b = set(df_b[column_validated])\n",
    "    \n",
    "    # Se hallan los datos del conjunto de df_personal que no estan en df_contract\n",
    "    difference_set_a = set_a - set_b\n",
    "    print('Cantidad de valores del conjunto de datos df_a que no estan en df_b: ', len(difference_set_a))\n",
    "    print('Datos de df_a que no estan en df_b: ', difference_set_a)\n",
    "    print('')\n",
    "    \n",
    "    # Se crea una lista con los datos de la columna customerid de df_a que no estan en df_b\n",
    "    list_difference_set_a = list(difference_set_a)\n",
    "\n",
    "    # S crea una lista para guardar las coincidencias\n",
    "    list_coincidense = []\n",
    "    \n",
    "    # Se listan los regitros del conjunto de datos df_consolidated que coinciden en la columna customerid con la lista list_personal\n",
    "    print('Codigos de cliente que tienen valores ausentes en df_consolidated')\n",
    "    for search_for_customer in list_difference_set_a:\n",
    "        row_search_for_customer = df_consolidated[df_consolidated[column_validated] == search_for_customer]\n",
    "        list_coincidense.append(search_for_customer)\n",
    "\n",
    "    print('-' * 80)\n",
    "    print(list_coincidense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635f3a8-d600-46e1-94b1-f176c018bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la funcion customer_validated para validar que clientes del df_personal no tiene un registro en el df_contract\n",
    "customer_validated(df_personal, df_contract, 'customerid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a62af1-41e9-4d3f-8265-b80918b7636c",
   "metadata": {},
   "source": [
    "Al observar los registros del dataframe df_consolidated que coinciden en su columna ***customerid*** con los elementos de la lista ***list_difference_set_a*** (clientes que no tiene contrato), se puede evidenciar que estos registros presenta valores ausentes porque no tiene un contrato. Motivo por el cual se procedera a eliminar estas filas, ya que representan el 0.15% del total de los registros y, este porcentaje no afecta el resultado que entregue el modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f9aa1-65aa-4cd3-9aec-d8a69f00c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de filas del conjunto de datos df_consolidated antes de eliminar los registros de los clientes que no tienen contrato\n",
    "print('tamaño inicial: ', df_consolidated.shape[0])\n",
    "\n",
    "# Se eliminan los registros de la columna begindate que tiene valores ausentes\n",
    "df_consolidated = df_consolidated.dropna(subset=['begindate'])\n",
    "\n",
    "# Numero de filas del conjunto de datos df_consolidated despues de eliminar los registros de los clientes que no tienen contrato\n",
    "print('tamaño final: ', df_consolidated.shape[0])\n",
    "\n",
    "display(df_consolidated.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f085201-5402-4b12-ac74-f69d2266ae39",
   "metadata": {},
   "source": [
    "***Analisis manejo de las columnas con valores ausentes en df_consilidated***\n",
    "\n",
    "Columnas procesadas:\n",
    "\n",
    "- ***begindate***: esta columna tenia valores ausentes porque pertenecian a clientes que no tenian un contrato.\n",
    "- ***type***: esta columna tenia valores ausentes porque pertenecian a clientes que no tenian un contrato.\n",
    "- ***paperlessbilling***: esta columna tenia valores ausentes porque pertenecian a clientes que no tenian un contrato.\n",
    "- ***paymentmethod***: esta columna tenia valores ausentes porque pertenecian a clientes que no tenian un contrato.\n",
    "- ***monthlycharges***: esta columna tenia valores ausentes porque pertenecian a clientes que no tenian un contrato.\n",
    "- ***totalcharges***: esta columna tenia valores ausentes porque pertenecian a clientes que no tenian un contrato.\n",
    "\n",
    "Acontinuacion de continua con el procesamiento de los valores ausentes de la columna multiplelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84004f0b-183d-4d82-aede-eed8ffeed7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la funcion customer_validated para validar que clientes del df_contract no tiene un registro en el df_phone\n",
    "customer_validated(df_contract, df_phone, 'customerid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c7c42-864a-4a1a-a1ac-b2f465de41a7",
   "metadata": {},
   "source": [
    "Al observar los registros del dataframe df_consolidated que coinciden en su columna ***customerid*** con los elementos de la lista ***list_difference_set_a*** (clientes que no tienen contratado el servicio de telefono), se observa que son el mismo numero de filas que tiene df_consolidated en su columna multiplelines con valores ausentes.\n",
    "\n",
    "La columna multiplelines solo maneja dos posible valores: ***yes*** y ***no***. Estos valores se reemplazaran por 1 para ***yes*** y 0 para ***no. Para los registros de df_consolidated que tiene valor ausente en la columna multiplelines, este valor se reemplazara por '***0***'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc74427-5cf4-4d16-81eb-0e194e4c7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De df_consolidated de su columna multiplelines se reemplazan los valores ausentes por '0' \n",
    "df_consolidated['multiplelines'].fillna('0', inplace=True)\n",
    "display(df_consolidated.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c33752-d855-48d8-b0a6-96c7ef09dacf",
   "metadata": {},
   "source": [
    "A continuacion de continua con el procesamiento de los valores ausentes de las siguientes columnas: internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport, streamingtv, streamingmovies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c95d47-6800-4739-98eb-e264aa999a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la funcion customer_validated para validar que clientes del df_contract no tiene un registro en el df_internet\n",
    "customer_validated(df_contract, df_internet, 'customerid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad72acd-7e94-4843-b412-6f1dd5a40200",
   "metadata": {},
   "source": [
    "Al observar los registros del dataframe df_consolidated que coinciden en su columna ***customerid*** con los elementos de la lista ***list_difference_set_a*** (clientes que no tienen contratado el servicio de internet), se observa que son el mismo numero de filas que tiene df_consolidated en sus columnas:  internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport, streamingtv, streamingmovies con valores ausentes.\r\n",
    "\r\n",
    "Se procede a revisar los valores unicos de las columnas con valores ausentes para determinar con que dato se debe reemplazar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccd755-6204-4aeb-856b-bdaaac901329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista con los nombres de las columnas que aun tienen valores ausentes en df_consolidated\n",
    "columns_null = df_consolidated.columns[df_consolidated.isnull().any()].tolist()\n",
    "\n",
    "for column in columns_null:\n",
    "    print('Valores unicos de la columna: ', column)\n",
    "    display(df_consolidated[column].unique())\n",
    "    print('-' * 80)\n",
    "\n",
    "# Se la lista de las columnas se elimina enddate, ya que esta no maneja valores yes y no \n",
    "if 'enddate' in columns_null:\n",
    "    columns_null.remove('enddate')  \n",
    "\n",
    "# Se la lista de las columnas se elimina internetservice, ya que esta no maneja valores yes y no \n",
    "if 'internetservice' in columns_null:\n",
    "    columns_null.remove('internetservice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b15ca-738f-4d0d-8d13-55b0b2c7e3de",
   "metadata": {},
   "source": [
    "La columna multiplelines solo maneja dos posible valores: ***yes*** y ***no***. Estos valores se reemplazaran por 1 para ***yes*** y 0 para ***no. Para los registros de df_consolidated que tiene valor ausente en la columna multiplelines, este valor se reemplazara por '***0***'\r\n",
    "\r\n",
    "\r\n",
    "Todas las columnas manejan solo dos posibles valores, ***yes*** y ***no***. Estos valores se reemplazaran por 1 para ***yes*** y 0 para ***no***. Para los registros de df_consolidated que tiene valor ausente en las columnas internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport y streamingtv, se reemplazarn con 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cbc4f4-33c7-4801-b45f-327120e579fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorrer la lista de las columnas para buscarlas en df_consolidated y hacer el respectivo cambio de valores\n",
    "for column_null in columns_null:\n",
    "    df_consolidated[column_null] = df_consolidated[column_null].map({'yes':'1', 'no':'0'}) \n",
    "\n",
    "# Se reemplazar por 0 los valores ausentes\n",
    "for column in columns_null:\n",
    "    df_consolidated[column].fillna('0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec976791-a12f-4474-920a-bc53d4b25dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los valores ausentes en la columna internetservice por no service \n",
    "df_consolidated['internetservice'].fillna('no service', inplace=True)\n",
    "\n",
    "display(df_consolidated.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1413664-7921-4b36-a7cb-00851e8da3bb",
   "metadata": {},
   "source": [
    "Al listar de nuevo los valores ausentes en df_consolidated, se puede observar que solo quedan ausentes los valores de la columna ***enddate*** y, estos valores representan a los clientes que aun tienen vigente su contrato, por este motivo no existe una fecha de finalizacion. \r\n",
    "\r\n",
    "Para poder tener una columna de objetivos en el dataframe, se adicionara una columna llamada ***finalizedcontract*** con valores de ***1*** para los datos que tiene una fecha asignada y ***0*** para los datos que tienen valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac03ce1-303e-4584-9809-478d1acf18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna finalizedcontract que se usara como objetivo para el modelo\n",
    "df_consolidated['finalizedcontract'] = df_consolidated['enddate'].map({'2019-12-01 00:00:00':'1', '2019-11-01 00:00:00':'1', '2020-01-01 00:00:00':'1', '2019-10-01 00:00:00':'1', 'no':'0'})\n",
    "print('')\n",
    "\n",
    "# Se revisan los valores unicos en la columna enddate\n",
    "print('Valores unicos en la columna enddate')\n",
    "display(df_consolidated['enddate'].unique()) \n",
    "print('')\n",
    "\n",
    "# Se revisan los valores unicos en la columna finalizedcontract\n",
    "print('Valores unicos en la columna finalizedcontract')\n",
    "display(df_consolidated['finalizedcontract'].unique()) \n",
    "\n",
    "# Se cambia el tipo de dato de la columna para evitar posibles errores en el entrenamiento de los modelos predictivos\n",
    "df_consolidated['finalizedcontract'] = df_consolidated['finalizedcontract'].astype('int')\n",
    "print('')\n",
    "\n",
    "# Se validan los valores de la nueva columna\n",
    "count_0 = df_consolidated['finalizedcontract'].value_counts()\n",
    "print('Numero de veces que se repiten los valores unicos en la columna finalizedcontract')\n",
    "print(count_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112bc716-66cd-417c-9df6-51ef06d40238",
   "metadata": {},
   "source": [
    "***Analisis de la columna finalizedcontract***\n",
    "\n",
    "La columna finalizedcontract que se usara como objetivo para el modelo presdictivo, tiene solo dos valores, 1 y 0. Siendo el 0 el valor que representa a los clientes que aun tiene su contrato vigente. El numero de veces que se repite el 0 en la columna es 5163, la columna tiene 11 filas menos con clientes que no tenian fecha de finalizacion. Estos 11 registros son los mismos que se eliminaron del df_personal pòr no tener un contrato asignado.\n",
    "\n",
    "Se procede a generar de nuevo los valores unicos en df_consolidated para verificar que los cambios efectudos se hallan aplicado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ca08f-845c-4700-b0a4-f6b40b285794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar los valores unicos en las columnas del nuevo conjunto de datos.\n",
    "columns = df_consolidated.columns\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    display(df_consolidated[column].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef9eee-e845-4aaa-a980-39e91d111a1a",
   "metadata": {},
   "source": [
    "Se realiza transformacion de columnas, separacion de caracteristicas y el objetivo para el entrenamiento del modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b078130-328f-4a3c-88c2-8ff92db8577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir la columna begindate para brindar mayor detalle al entrenamiento del modelo\n",
    "df_consolidated['yearbegindate'] = df_consolidated['begindate'].dt.year\n",
    "df_consolidated['mesbegindate'] = df_consolidated['begindate'].dt.month\n",
    "df_consolidated['diabegindate'] = df_consolidated['begindate'].dt.day\n",
    "\n",
    "# Las columnas mesbegindate y diabegindate se pasan a tipo objecto por tener datos con clasificacion ordinal\n",
    "df_consolidated['mesbegindate'] = df_consolidated['mesbegindate'].astype('object')\n",
    "df_consolidated['diabegindate'] = df_consolidated['mesbegindate'].astype('object')\n",
    "\n",
    "# Se extraen las caracteristicas y el objetivo para el entrenamiento del modelo\n",
    "features = df_consolidated.drop(columns=['customerid', 'begindate', 'enddate', 'finalizedcontract'])\n",
    "target = df_consolidated['finalizedcontract']\n",
    "\n",
    "# Se separan los nombres de las columnas segun el tipo de dato para la posterior codificacion o escalado\n",
    "categorical_columns = features.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_columns = features.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "\n",
    "print('Total columnas tipo objetc: ', len(categorical_columns))\n",
    "print('Total columnas tipo numerico: ',len(numeric_columns))\n",
    "\n",
    "print('')\n",
    "print('Total filas en features: ', features.shape[0])\n",
    "print('Total columnas en features: ', features.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ae3ca-5d32-4169-888a-d3aa9f2d5cab",
   "metadata": {},
   "source": [
    "### 3.1.2 Análisis exploratorio de datos (EDA)\r\n",
    "\r\n",
    "Validacion de balance de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e174e-4f2b-4fc2-bd5d-19dc6edcc320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera el conteo para cada clase en el objetivo\n",
    "class_counts = target.value_counts()\n",
    "    \n",
    "print('Balance de clases para el objetivo: ', class_counts)\n",
    "    \n",
    "# Gráfico de barras para el balance de clases\n",
    "sns.countplot(x=target)\n",
    "plt.title(\"Balance de Clases en el Objetivo\")\n",
    "plt.xlabel(\"Clase\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88879a-2d2b-431a-867d-c168517f5f3e",
   "metadata": {},
   "source": [
    "Codificacion y escalado de las caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a162b2-d060-4896-a327-623f2d2e6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escaladar de las caracteristicas nunericas\n",
    "scaler = StandardScaler()\n",
    "columns_scaled = {}\n",
    "\n",
    "# Se recorren las columnas numericas para usar la barra tqdm\n",
    "for column in tqdm(numeric_columns, 'Escalado de olumnas numericas'):\n",
    "    # Se escala una a una las columnas\n",
    "    columns_scaled[column] = scaler.fit_transform(features[[column]])\n",
    "\n",
    "# Se transforma en dataframe el resultado del escalado\n",
    "df_columns_scaled = pd.DataFrame({col: columns_scaled[col].flatten() for col in numeric_columns})\n",
    "\n",
    "# Codificacion de las columnas categoricas\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "columns_encode = []\n",
    "\n",
    "# Se recorren las columnas numericas para usar la barra tqdm\n",
    "for column in tqdm(categorical_columns, desc='Codificación de columnas categóricas'):\n",
    "    encoded_column = encoder.fit_transform(features[[column]])  #  Se codifica cada columna individualmente\n",
    "    column_names = [f\"{column}_{cat}\" for cat in encoder.categories_[0]]  # Se generan nombres únicos para las columnas\n",
    "    encoded_df = pd.DataFrame(encoded_column, columns=column_names)  # Se crea un DataFrame para la columna codificada\n",
    "    columns_encode.append(encoded_df)  # Agrega al listado de DataFrames codificados\n",
    "\n",
    "# Combina todas las columnas codificadas en un solo DataFrame\n",
    "df_columns_encode = pd.concat(columns_encode, axis=1)\n",
    "\n",
    "# Se combinan los resultados\n",
    "features_transform = pd.concat([df_columns_scaled, df_columns_encode], axis=1)\n",
    "\n",
    "print('Numero de filas en el conjunto de caracteristicas despues del escalado y la codificacion: ', features_transform.shape[0])\n",
    "print('Numero de columnas en el conjunto de caracteristicas despues del escalado y la codificacion: ', features_transform.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d5b3d-da1c-4071-9a81-6aff8d04cd49",
   "metadata": {},
   "source": [
    "Separacion de los conjuntos de entrenamiento y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2396c-dcc3-475f-9a92-d9c2fff8c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar espacios al inicio y al final, y reemplazar espacios en medio por guiones bajos\n",
    "features_transform.columns = features_transform.columns.str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Se separan los conjuntos de datos para entrenammiento y validacion\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_transform, target, random_state=12345, test_size=0.2)\n",
    "\n",
    "# Se verifica del tamaño de los conjuntos de entrenamiento y validacion\n",
    "print('Numero de filas del conjunto de entrenamiento: ', features_train.shape[0]) \n",
    "print('Numero de columnas del conjunto de entrenamiento: ', features_train.shape[1]) \n",
    "print('Numero de filas del objetivo para el entrenamiento: ', target_train.shape[0])\n",
    "print('')\n",
    "\n",
    "print('Numero de filas del conjunto de validacion: ', features_test.shape[0])\n",
    "print('Numero de columnas del conjunto de validacion: ', features_test.shape[1])\n",
    "print('Numero de filas del objetivo para el entrenamiento: ', target_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d10750-b3ef-4f72-809e-87db569f33f4",
   "metadata": {},
   "source": [
    "Sobremuestreo de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a2095-2f5f-4136-9642-4351e9a1c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar el conteo para cada clase en el objetivo de entrenamiento\n",
    "class_counts = target_train.value_counts()\n",
    "print('Balance original de clases para el objetivo de entrenamiento: ', class_counts)\n",
    "print('')\n",
    "\n",
    "# Se aplica SMOTE al conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "features_train_resampled, target_train_resampled = smote.fit_resample(features_train, target_train)\n",
    "\n",
    "# Se verificar la nueva distribución de clases\n",
    "class_counts = target_train_resampled.value_counts()\n",
    "print('Balance con sobremuestreo de clases para el objetivo de entrenamiento: ', class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7b007d-a6c3-47fe-bf82-e17491f1f976",
   "metadata": {},
   "source": [
    "## 4. Construcción del Modelo Predictivo\n",
    "\n",
    "\n",
    "Funcion para evaluar el resultado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8381ba-bac0-4b67-a9b8-a00d54af6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_classification(value_metric):\n",
    "    \"\"\"\n",
    "    La funcion recibe el resultado de la metrica obtenido para la curva ROC\n",
    "    y lo clasifica segun los rangos entregados en el proyecto. Esta funcion se uitiliza en cada uno de los modelos,\n",
    "    despues de haber realizado las predicciones.\n",
    "    \n",
    "    Parametros:\n",
    "    value_metric: valor de la metrica curve roc\n",
    "    \n",
    "    Return\n",
    "    La funcion retorna el valor de SP asignado segun el resultado de la curva ROC\n",
    "    \"\"\"\n",
    "    if value_metric < 0.75:\n",
    "        sp = 0\n",
    "    elif 0.75 <= value_metric < 0.81:\n",
    "        sp = 4\n",
    "    elif 0.81 <= value_metric < 0.85:\n",
    "        sp = 4.5\n",
    "    elif 0.85 <= value_metric < 0.87:\n",
    "        sp = 5\n",
    "    elif 0.87 <= value_metric < 0.88:\n",
    "        sp = 5.5\n",
    "    else:\n",
    "        sp = 6\n",
    "\n",
    "    return sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f56d3-6fdb-41df-a417-ab78d250b176",
   "metadata": {},
   "source": [
    "Funcion para graficar el resultado de la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f431d4-f9d3-46ab-85a6-9b05e9e5e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_roc(probability, title, value, target_test):\n",
    "    \"\"\"\n",
    "    La funcion grafica los resultados de las probabilidades usando la curva de ROC.\n",
    "    Esta funcion se utiliza en cada modelo despues de realizadas las predicciones.\n",
    "    \n",
    "    Parametros:\n",
    "    probability: son las probabilidades que tiene la clase 1 de ser predichas por el modelo.\n",
    "    title:  es el mombre del modelo usado.\n",
    "    value: es el valor de la metrica obtenida.\n",
    "    \n",
    "    Return\n",
    "    La funcion genera el grafico de la curva de ROC\n",
    "    \"\"\"\n",
    "    # Curva ROC\n",
    "    target_test = target_test.astype(int)\n",
    "    title = 'Curva ROC - ' + title\n",
    "    fpr, tpr, thresholds = roc_curve(target_test, probability)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC-ROC = {value:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label=\"Random Guess\")\n",
    "    plt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\n",
    "    plt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e2f1fe-1fc3-45d4-9cb0-4dca65da6b63",
   "metadata": {},
   "source": [
    "Funcion para calcular las metricas objetvo del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407afca2-52b5-42f5-b6f6-485af089911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, predictions, resampled, feature_test, target_test, time, name_model):\n",
    "        \"\"\"\n",
    "        La funcion calcula las metricas del modelo que se solicitan en el proyecto para poder validar la exactitud de las\n",
    "        predicciones realizadas y guarda los datos en la lista correspondiente. Estos datos se almacena en listas diferentes para \n",
    "        poder identificar los resultados de trabajar con datos sin y con sobremuestreo\n",
    "    \n",
    "        Parametros:\n",
    "        model: es el modelo que se entreno.\n",
    "        predictions: son las predicciones realizadas por el modelo entrenado.\n",
    "        feature_test: son las caracteristicas que se usan para calcular las probabilidades de que el modelo prediga la clase positiva.\n",
    "        target_test: son los objetivos que se usan para hallar las metricas accuracy y la curva de roc.\n",
    "        time: es el tiempo que tardo el modelo en entrenarse y generar predicciones.\n",
    "        name_model: es el nombre del modelo que permite el numero del modelo y el algoritmo utilizado.\n",
    "    \n",
    "        Retorno:\n",
    "        La funcion no tiene retorno. Los datos obtenidos se muestran en pantalla y se almacenan en listas para ser procesados posteriormente.\n",
    "        \"\"\"\n",
    "        # Se obtienen las probabilidades que tiene el modelo para predecir la clase positiva\n",
    "        probabilities = model.predict_proba(feature_test)[:, 1]  # Probabilidades para la clase positiva\n",
    "        \n",
    "        # Cálculo de métricas\n",
    "        accuracy = accuracy_score(target_test, predictions)\n",
    "        auc_roc = roc_auc_score(target_test, probabilities)  \n",
    "        logloss = log_loss(target_test, probabilities)\n",
    "\n",
    "        print(f\"Exactitud (Accuracy): {accuracy:.2f}\")\n",
    "        print(f\"AUC-ROC: {auc_roc:.2f}\")\n",
    "        print(f\"Valor logLoss : {logloss:.2f}\")\n",
    "        \n",
    "        # Se obtiene la clasificacion del valor obtenido en la metrica de la curva ROC\n",
    "        classification_metric = result_classification(auc_roc)\n",
    "        print('Clasificion SP obtenida por el modelo: ', classification_metric)\n",
    "         \n",
    "        # Se genera el grafico de la curva de ROC\n",
    "        curve_roc(probabilities, name_model, auc_roc, target_test)\n",
    "        \n",
    "        # Se obtienen los mejores valores de hiperparametros\n",
    "        parameters = grid_search.best_params_\n",
    "    \n",
    "        if resampled == 'No':\n",
    "            # Se guardan los resultados entregados por el modelo sin sobremuestreo\n",
    "            models_results.append({\n",
    "            'Modelo': name_model,\n",
    "            'Parametros':parameters,\n",
    "            'Segundos':round(time,2),\n",
    "            'SP':classification_metric,\n",
    "            'AUC-ROC': round(auc_roc,2),\n",
    "            'Precision': round(accuracy,2),\n",
    "            'log_loss':round(logloss,2),    \n",
    "            'Sobremuestreo': resampled\n",
    "             })\n",
    "        else:\n",
    "            # Se guardan los resultados entregados por el modelo\n",
    "            models_results_resampled.append({\n",
    "            'Modelo': name_model,\n",
    "            'Parametros':parameters,\n",
    "            'Segundos':round(time,2),\n",
    "            'SP':classification_metric,\n",
    "            'AUC-ROC': round(auc_roc,2),\n",
    "            'Precision': round(accuracy,2),\n",
    "            'log_loss':round(logloss,2),\n",
    "            'Sobremuestreo': resampled\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1ccb5-086f-40e2-9b4e-fa2413a0f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para guardar las metricas generadas por los modelos sin hacer ajustes en el balance de clases\n",
    "models_results = []\n",
    "\n",
    "# Lista para guardar las metricas generadas por los modelos con sobremuestreo en el balance de clases\n",
    "models_results_resampled = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a40c4d-ffa8-4b82-b611-c3350ec86883",
   "metadata": {},
   "source": [
    "Funcion para entrenar el modelo y generar predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6002a3-b8b3-4e1f-a07a-85e3da62e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_generate_predictions(model, parameters, f_train, t_train, f_test):\n",
    "    \"\"\"\n",
    "    La funcion recibe el modelo predictivo, los parametros para el modelo y los conjuntos de datos para entrenarse\n",
    "    y generar predcciones.\n",
    "\n",
    "    Parametros:\n",
    "    model: es el modelo que entrenara y generara las predicciones.\n",
    "    parameters: es el conjunto de los mejores que usara el modelo para su entrenamiento.\n",
    "    f_train: son las caracteristicas que usara el modelo para su entrenamiento.\n",
    "    t_train: es el conjunto de datos que se usaran como objetivo en el entrenamiento.\n",
    "\n",
    "    Return\n",
    "    La funcion retorna los siguientes datos:\n",
    "    grid_search: es el modelo que se usara para poder generar las predicciones de la clase positiva y asi encontrar el valor de\n",
    "    la curva de ROC.\n",
    "    predictions: son los resultados entregados por el modelo despues de ser entrenado que se usan para hallar la metrica accuracy.\n",
    "    total_time: es el tiempo en minutos que tarda el modelo en ser entrenado y generar predicciones. Este dato se almacena en una lista\n",
    "    para despues poder comparar los resultados de todos los modelos entrenados.\n",
    "    \"\"\"\n",
    "    # Se inicializan las variables que llevan el control del tiempo que tarda el modelo en ser entrenado y generar predicciones\n",
    "    start_time = 0\n",
    "    end_time = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    # Configuracion de la validación cruzada con GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    cv=2,                # Número de particiones de validación cruzada\n",
    "    scoring='accuracy',  # Métrica de evaluación\n",
    "    n_jobs=-1            # Usar todos los núcleos disponibles\n",
    "    )\n",
    "\n",
    "    # Inicia el tiempo de ejecucion del modelo\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Entrenar con los datos de entrenamiento sin sobremuestreo\n",
    "    grid_search.fit(f_train, t_train)\n",
    "    \n",
    "    # Evaluar el modelo con los mejores parámetros en los datos de prueba\n",
    "    best_model = grid_search.best_estimator_\n",
    "    predictions = best_model.predict(f_test)\n",
    "    \n",
    "    # Finaliza el tiempo de ejecucion del modelo\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calcula los segudos que tarda el modelo en su entrenamiento y en hacer las predicciones\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    return grid_search, predictions, total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b8833-d885-4d17-a81a-8ac69b381a94",
   "metadata": {},
   "source": [
    "Defincion de hiperparametros para ***LogisticRegression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83161adb-69ad-43f7-a603-f9a0577c3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan posibles espacios en blanco en los nombres de las columnas\n",
    "features_train.columns = features_train.columns.str.replace(\" \", \"_\")\n",
    "features_train_resampled.columns = features_train_resampled.columns.str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec27c55-8342-46a7-bb9f-2898a3bc1356",
   "metadata": {},
   "source": [
    "Entrenamiento y validacion de los modelos predictivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc2a06-d422-439b-8d46-5ebad1ee8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejilla de hiperparametros\n",
    "param_grid_LogisticRegression = {\n",
    "    \"penalty\": [\"l2\"],             # Regularización aplicada (l2 es Ridge regularization)\n",
    "    \"solver\": [\"lbfgs\"],           # Algoritmo de optimización utilizado para ajustar el modelo\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],  # Inverso de la fuerza de regularización; valores más altos implican menos regularización\n",
    "    \"max_iter\": [100, 200, 1000]    # Número máximo de iteraciones permitidas para la convergencia del solver\n",
    "}\n",
    "\n",
    "# Creacion del modelo\n",
    "model_1_logistic_regression = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365337bb-1b45-4c09-97de-f7e010567bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un diccionario para guardar los nombres y los modelos con sus respectivos parametros\n",
    "models = {}\n",
    "\n",
    "# Se crea un diccionario para guardar los nombres y los modelos con sus respectivos parametros de los modelos con sobremuestreo\n",
    "models_resampled = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d58c588-7c82-4c48-933f-5ee311c0e415",
   "metadata": {},
   "source": [
    "***Modelo LogisticRegression***\n",
    "\n",
    "Datos sin sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1a009-617b-43fc-b80e-2e86d5f31d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar a la funcion para entregar el modelo y generar predicciones\n",
    "grid_search, predictions, total_time = train_model_generate_predictions(model_1_logistic_regression, param_grid_LogisticRegression, features_train, target_train, features_test)\n",
    "\n",
    "# LLamar a la funcion para calcular las metricas objetivo\n",
    "calculate_metrics(grid_search, predictions, 'No', features_test, target_test, total_time, 'Model_1_LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d00eca-c1ab-40c0-a2df-b31ae243c77e",
   "metadata": {},
   "source": [
    "***Modelo LogisticRegression***\n",
    "\n",
    "Datos con sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a119dc-ff86-400d-9f8d-0e5c360d3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar a la funcion para entregar el modelo y generar predicciones\n",
    "grid_search, predictions, total_time = train_model_generate_predictions(model_1_logistic_regression, param_grid_LogisticRegression, features_train_resampled, target_train_resampled, features_test)\n",
    "\n",
    "# LLamar a la funcion para calcular las metricas objetivo\n",
    "calculate_metrics(grid_search, predictions, 'Si', features_test, target_test, total_time, 'Model_1_LogisticRegression_resampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c5d7b-8830-46e5-ba9f-5b32dc6721e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el nombre y la configuracion del modelo para usar con SHAP\n",
    "models['Model_1_LogisticRegression'] = grid_search.best_estimator_\n",
    "\n",
    "models_resampled['Model_1_1_LogisticRegression'] = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a42fb2-7ed3-485e-847c-ca7728b5514d",
   "metadata": {},
   "source": [
    "Defincion de hiperparametros para ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd1841-a90f-4b71-acae-72593d27c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejilla de hiperparametros\n",
    "param_grid_RandomForestClassifier = {\n",
    "    'n_estimators': [10, 20, 40],         # Numero de arboles en el bosque\n",
    "    'max_depth': [5, 10, 15],             # Profundidad maxima de los arboles\n",
    "    'max_features': ['sqrt', 'log2'],     # Numero maximo de caracteristcas a considerar en cada division\n",
    "    'min_samples_split': [2, 5, 10]       # Numero minimo de muestras necesarias para dividir un nodo interno\n",
    "}\n",
    "\n",
    "# Creacion del modelo\n",
    "model_2_Random_Forest_Classifier = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f1cf6-ad6c-4c13-a584-e1d177f0bf01",
   "metadata": {},
   "source": [
    "***Modelo RandomForestClassifier***\n",
    "\n",
    "Datos sin sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f021a04-e16e-44da-9d63-4ca82d1ac182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar a la funcion para entregar el modelo y generar predicciones\n",
    "grid_search, predictions, total_time = train_model_generate_predictions(model_2_Random_Forest_Classifier, param_grid_RandomForestClassifier, features_train, target_train, features_test)\n",
    "\n",
    "# LLamar a la funcion para calcular las metricas objetivo\n",
    "calculate_metrics(grid_search, predictions, 'No', features_test, target_test, total_time, 'Model_2_RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec31565-751b-490c-a8a8-6b4d06bbb8d8",
   "metadata": {},
   "source": [
    "***Modelo RandomForestClassifier***\n",
    "\n",
    "Datos con sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfddad1-643f-43ef-98c5-c11aa8cbe0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar a la funcion para entregar el modelo y generar predicciones\n",
    "grid_search, predictions, total_time = train_model_generate_predictions(model_2_Random_Forest_Classifier, param_grid_RandomForestClassifier, features_train_resampled, target_train_resampled, features_test)\n",
    "\n",
    "# LLamar a la funcion para calcular las metricas objetivo\n",
    "calculate_metrics(grid_search, predictions, 'Si', features_test, target_test, total_time, 'Model_2_RandomForestClassifier_resampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb84f9a-3d61-4589-ae42-411471d48568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el nombre y la configuracion del modelo\n",
    "models['Model_2_RandomForestClassifier'] = grid_search.best_estimator_\n",
    "models_resampled['Model_2_2_RandomForestClassifier'] = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d54c9a1-77e1-4e1a-9594-18c458f4df76",
   "metadata": {},
   "source": [
    "Defincion de hiperparametros para ***XGBClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8fe60-e609-419a-a01c-7509f6abdb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejilla de hiperparametros\n",
    "param_grid_XGBClassifier = {\n",
    "    'n_estimators': [10, 20, 40],              # Numero de arboles en el bosque\n",
    "    'max_depth': [5, 10, 15],                  # Profundidad maxima de los arboles\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],       # Proporcion de caracteristicas usadas por arbol\n",
    "    'min_child_weight': [1, 3, 5]              # Peso minimo total requerido en un nodo hoja\n",
    "}\n",
    "\n",
    "# Creacion del modelo\n",
    "model_3_XGBClassifier = XGBClassifier(random_state=42, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839607f4-795c-49c7-aea7-5f70f63b48e7",
   "metadata": {},
   "source": [
    "***Modelo XGBClassifier***\n",
    "\n",
    "Datos sin sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96aea1-97ad-44ca-8908-0f715578aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar a la funcion para entregar el modelo y generar predicciones\n",
    "grid_search, predictions, total_time = train_model_generate_predictions(model_3_XGBClassifier, param_grid_XGBClassifier, features_train, target_train, features_test)\n",
    "\n",
    "# LLamar a la funcion para calcular las metricas objetivo\n",
    "calculate_metrics(grid_search, predictions, 'No', features_test, target_test, total_time, 'Model_3_XGBClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc6dfe-2911-44c9-ad51-89eb596b29ca",
   "metadata": {},
   "source": [
    "***Modelo XGBClassifier***\n",
    "\n",
    "Datos con sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d4be7-551b-4c2a-a1b0-614530337f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar a la funcion para entregar el modelo y generar predicciones\n",
    "grid_search, predictions, total_time = train_model_generate_predictions(model_3_XGBClassifier, param_grid_XGBClassifier, features_train_resampled, target_train_resampled, features_test)\n",
    "\n",
    "# LLamar a la funcion para calcular las metricas objetivo\n",
    "calculate_metrics(grid_search, predictions, 'Si', features_test, target_test, total_time, 'Model_3_XGBClassifier_resampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0587b-52a3-4836-860f-0c97f6b44fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el nombre y la configuracion del modelo\n",
    "models['Model_3_XGBClassifier'] = grid_search.best_estimator_\n",
    "models_resampled['Model_3_3_XGBClassifier'] = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56370cd-1ead-41db-9e11-c9720967aa2f",
   "metadata": {},
   "source": [
    "Defincion de hiperparametros para ***LGBMClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e8b38-62e0-4495-ad15-94eb385b57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejilla de hiperparametros\n",
    "param_grid_LGBMClassifier = {\n",
    "    'n_estimators': [10, 20, 40],               # Numero de arboles en el bosque\n",
    "    'max_depth': [5, 10, 15],                   # Profundidad maxima de los arboles\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],        # Proporcion de caracteristicas usadas por arbol\n",
    "    'min_child_samples': [1, 3, 5]              # Numero minimo requerido de muestras en una hoja\n",
    "}\n",
    "\n",
    "# Creacion del modelo\n",
    "model_4_LGBMClassifier = LGBMClassifier(random_state=42, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37896e-8e54-4de5-b1f6-88df217931ba",
   "metadata": {},
   "source": [
    "***Modelo LGBMClassifier***\n",
    "\n",
    "Datos sin sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1266ce5-afe1-43cb-aa30-97a1826b02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar a la funcion para entregar el modelo y generar predicciones\n",
    "grid_search, predictions, total_time = train_model_generate_predictions(model_4_LGBMClassifier, param_grid_LGBMClassifier, features_train, target_train, features_test)\n",
    "\n",
    "# LLamar a la funcion para calcular las metricas objetivo\n",
    "calculate_metrics(grid_search, predictions, 'No', features_test, target_test, total_time, 'Model_4_LGBMClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96792c26-d1e1-464a-ac31-fc1e1f78e614",
   "metadata": {},
   "source": [
    "***Modelo LGBMClassifier***\n",
    "\n",
    "Datos con sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a71a16-587a-4a2d-a24e-c21540e1ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar a la funcion para entregar el modelo y generar predicciones\n",
    "grid_search, predictions, total_time = train_model_generate_predictions(model_4_LGBMClassifier, param_grid_LGBMClassifier, features_train_resampled, target_train_resampled, features_test)\n",
    "\n",
    "# LLamar a la funcion para calcular las metricas objetivo\n",
    "calculate_metrics(grid_search, predictions, 'Si', features_test, target_test, total_time, 'Model_4_LGBMClassifier_resampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14fe1d-345b-4ed8-9a11-f25e6fb5041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el nombre y la configuracion del modelo\n",
    "models['Model_4_LGBMClassifier'] = grid_search.best_estimator_\n",
    "models_resampled['Model_4_4_LGBMClassifier'] = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189acb7f-e906-4054-8879-38a223e75966",
   "metadata": {},
   "source": [
    "## 5. Interpretación de Resultados\n",
    "\n",
    "### Importancia de características:\r\n",
    "- Identificar las variables que más contribuyen a la predicción\n",
    "\n",
    "Analisis de caracteristicas sin sobre muestreo y definicion del umbral para eliminar las caracteristicas de menos relevancia para las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11174764-4846-4df1-b879-a291973857ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_features_train_shap = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Analisis SHAP para {name} \\n\")\n",
    "    \n",
    "    if name == \"Model_2_RandomForestClassifier\":\n",
    "        explainer = shap.Explainer(model, features_train)  \n",
    "        shap_values = explainer(features_test, check_additivity=False)\n",
    "        mean_shap = shap_values.values.mean(axis=0)\n",
    "        \n",
    "        # Reducir dimensiones para que mean_shap sea un vector\n",
    "        if mean_shap.ndim == 2:\n",
    "        # Tomar promedio absoluto a través de las clases\n",
    "           mean_shap = np.abs(mean_shap).mean(axis=1)\n",
    "    \n",
    "    else:\n",
    "        # Para otros modelos como logisticregression, xgbclassifier, lgbmclassifier\n",
    "        explainer = shap.Explainer(model, features_train)  \n",
    "        shap_values = explainer(features_test)\n",
    "        mean_shap = shap_values.values.mean(axis=0)\n",
    "        \n",
    "    # Procesar los valores SHAP como antes\n",
    "    print('shape mean_shap', mean_shap.shape)\n",
    "    print('Validacion de longitures para features_train y mean_shap -->', len(features_train.columns), len(mean_shap))\n",
    "    \n",
    "    features_importance = pd.DataFrame({'feature': features_train.columns, 'Mean SHAP Value': mean_shap})\n",
    "    features_importance = features_importance.sort_values(by='Mean SHAP Value', ascending=False)\n",
    "    \n",
    "    print(f'Caracteristicas mas importantes para {name} :\\n')\n",
    "    display(features_importance.head(20))\n",
    "\n",
    "    # Definicion del umbral del 5% del valor maximo\n",
    "    threshold = 0.05 * features_importance['Mean SHAP Value'].max()\n",
    "    features_to_remove = features_importance[features_importance['Mean SHAP Value'] < threshold]['feature'].values\n",
    "    features_train_shap = features_train.drop(columns=features_to_remove)\n",
    "    dfs_features_train_shap[name] = features_train_shap\n",
    "    view_columns = pd.DataFrame(dfs_features_train_shap[name])\n",
    "\n",
    "    print('')\n",
    "    print('Numero de caracteristicas antes de apilcar shap -->: ', features_train.shape[1])\n",
    "    print('Numero de caracteristicas despues de apilcar shap -->: ', view_columns.shape[1])\n",
    "    \n",
    "    print('-' * 120)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28ec0b-60fa-4c2c-83d5-a110c1686306",
   "metadata": {},
   "source": [
    "Analisis de caracteristicas con sobre muestreo y definicion del umbral para eliminar las caracteristicas de menos relevancia para las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce893d7e-f5ab-49f3-bae8-440b11e9ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para almacenar las columnas que superan el umbral definido despues de hallar los valores SHAP\n",
    "dfs_features_train_resampled_shap = {}\n",
    "\n",
    "for name, model in models_resampled.items():\n",
    "    print(f\"Analisis SHAP para {name} \\n\")\n",
    "    \n",
    "    if name == \"Model_2_2_RandomForestClassifier\":\n",
    "        explainer = shap.Explainer(model, features_train_resampled)  # Eliminamos el 'masker'\n",
    "        shap_values = explainer(features_test, check_additivity=False)\n",
    "        mean_shap = shap_values.values.mean(axis=0)\n",
    "    \n",
    "       \n",
    "        # Reducir dimensiones para que mean_shap sea un vector\n",
    "        if mean_shap.ndim == 2:\n",
    "        # Tomar promedio absoluto a través de las clases\n",
    "           mean_shap = np.abs(mean_shap).mean(axis=1)    \n",
    "        \n",
    "    else:\n",
    "        # Para otros modelos como logisticregression, xgbclassifier, lgbmclassifier\n",
    "        explainer = shap.Explainer(model, features_train_resampled)  # Eliminamos el 'masker'\n",
    "        shap_values = explainer(features_test)\n",
    "        mean_shap = shap_values.values.mean(axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    # Procesar los valores SHAP como antes\n",
    "    print('shape mean_shap', mean_shap.shape)\n",
    "    print('Validacion de longitures para features_train y mean_shap -->', len(features_train_resampled.columns), len(mean_shap))\n",
    "    \n",
    "    features_resampled_importance = pd.DataFrame({'feature': features_train_resampled.columns, 'Mean SHAP Value': mean_shap})\n",
    "    features_resampled_importance = features_resampled_importance.sort_values(by='Mean SHAP Value', ascending=False)\n",
    "    \n",
    "    print(f'Caracteristicas mas importantes para {name} :\\n')\n",
    "    display(features_resampled_importance.head(20))\n",
    "\n",
    "    # Definicion del umbral del 5%\n",
    "    threshold = 0.05 * features_resampled_importance['Mean SHAP Value'].max()\n",
    "    features_to_remove = features_resampled_importance[features_resampled_importance['Mean SHAP Value'] < threshold]['feature'].values\n",
    "    features_train_resampled_shap = features_train_resampled.drop(columns=features_to_remove)\n",
    "    dfs_features_train_resampled_shap[name] = features_train_resampled_shap\n",
    "    view_columns = pd.DataFrame(dfs_features_train_resampled_shap[name])\n",
    "\n",
    "    print('')\n",
    "    print('Numero de caracteristicas antes de apilcar shap -->: ', features_train_resampled.shape[1])\n",
    "    print('Numero de caracteristicas despues de apilcar shap -->: ', view_columns.shape[1])\n",
    "    \n",
    "    print('-' * 120)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbfae0-10ae-4361-ad95-920f5c0785d4",
   "metadata": {},
   "source": [
    "### Resultados esperados:\n",
    "- Lograr al menos un AUC-ROC de 0.81 para cumplir con los criterios de evaluación de 4.5 SP.\n",
    "\n",
    "\n",
    "\n",
    "***Modelo LogisticRegression usando SHAP***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef078844-3faf-44e2-ae65-7bf66942dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del modelo\n",
    "model_1_logistic_regression = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbd6d3-4a42-4338-8265-7fb43e5d8249",
   "metadata": {},
   "source": [
    "Datos sin sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7c493-d0de-4dce-82b5-dc70a013916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_shap = pd.DataFrame(dfs_features_train_shap['Model_1_LogisticRegression'])\n",
    "\n",
    "features_train_shap, features_test_shap, target_train_shap, target_test_shap = train_test_split(features_shap, target_train, random_state=12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79922c-f90a-4865-b976-3d8bc847ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, predictions, total_time = train_model_generate_predictions(model_1_logistic_regression, param_grid_LogisticRegression, features_train_shap, target_train_shap, features_test_shap)\n",
    "\n",
    "calculate_metrics(grid_search, predictions, 'No', features_test_shap, target_test_shap, total_time, 'Model_1_LogisticRegression_Shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc83c1-f263-49b9-a401-0090ba35cd0b",
   "metadata": {},
   "source": [
    "Datos con sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b551e0-4944-4d1f-bcf3-5c034f973be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_resampled_shap = pd.DataFrame(dfs_features_train_resampled_shap['Model_1_1_LogisticRegression'])\n",
    "\n",
    "features_train_shap, features_test_shap, target_train_shap, target_test_shap = train_test_split(features_resampled_shap, target_train_resampled, random_state=12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506575c2-7303-4ce3-9d8c-d06b14b4333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, predictions, total_time = train_model_generate_predictions(model_1_logistic_regression, param_grid_LogisticRegression, features_train_shap, target_train_shap, features_test_shap)\n",
    "\n",
    "calculate_metrics(grid_search, predictions, 'Si', features_test_shap, target_test_shap, total_time, 'Model_1_LogisticRegression_resampled_Shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913a55e-148c-4309-b8c9-29d4f88efae0",
   "metadata": {},
   "source": [
    "***Modelo RandomForestClassifier usando SHAP***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe82270-82c3-47d9-be7c-51df02f81ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del modelo\n",
    "model_2_Random_Forest_Classifier = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4b1f3-6932-4302-abaf-ef85cd138db0",
   "metadata": {},
   "source": [
    "Datos sin sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7fb1b4-481f-4f8d-a499-a70d608e8377",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_shap = pd.DataFrame(dfs_features_train_shap['Model_2_RandomForestClassifier'])\n",
    "\n",
    "features_train_shap, features_test_shap, target_train_shap, target_test_shap = train_test_split(features_shap, target_train, random_state=12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18088fef-8482-47e8-8313-9e0ee0e3936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, predictions, total_time = train_model_generate_predictions(model_2_Random_Forest_Classifier, param_grid_RandomForestClassifier, features_train_shap, target_train_shap, features_test_shap)\n",
    "\n",
    "calculate_metrics(grid_search, predictions, 'No', features_test_shap, target_test_shap, total_time, 'Model_2_RandomForestClassifier_shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad8e1cc-318b-434c-ba08-1f9a27dd8cd3",
   "metadata": {},
   "source": [
    "Datos con sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0cf67-c1b9-4028-afb1-53e8a0bd66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_resampled_shap = pd.DataFrame(dfs_features_train_resampled_shap['Model_2_2_RandomForestClassifier'])\n",
    "\n",
    "features_train_shap, features_test_shap, target_train_shap, target_test_shap = train_test_split(features_resampled_shap, target_train_resampled, random_state=12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7e025-cf73-4ba5-917b-32458c8aec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, predictions, total_time = train_model_generate_predictions(model_2_Random_Forest_Classifier, param_grid_RandomForestClassifier, features_train_shap, target_train_shap, features_test_shap)\n",
    "\n",
    "calculate_metrics(grid_search, predictions, 'Si', features_test_shap, target_test_shap, total_time, 'Model_2_RandomForestClassifier_resampled_Shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094caca-d385-480c-8546-d2257c8e9d7c",
   "metadata": {},
   "source": [
    "***Modelo XGBClassifier usando SHAP***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234cc9e3-1c24-4597-98fd-1de79716bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del modelo\n",
    "model_3_XGBClassifier = XGBClassifier(random_state=42, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d974a7-21fe-4832-a324-33fcbe23abbd",
   "metadata": {},
   "source": [
    "Datos sin sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b30f21-9a78-48f9-a4ab-a02a922e4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_shap = pd.DataFrame(dfs_features_train_shap['Model_3_XGBClassifier'])\n",
    "\n",
    "features_train_shap, features_test_shap, target_train_shap, target_test_shap = train_test_split(features_shap, target_train, random_state=12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd59e16-ee9c-4a0e-b5d0-56c7a04466d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, predictions, total_time = train_model_generate_predictions(model_3_XGBClassifier, param_grid_XGBClassifier, features_train_shap, target_train_shap, features_test_shap)\n",
    "\n",
    "calculate_metrics(grid_search, predictions, 'No', features_test_shap, target_test_shap, total_time, 'model_3_XGBClassifier_shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a0800e-e72f-490a-8fc1-eaffc2ee336a",
   "metadata": {},
   "source": [
    "Datos con sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3851d91-45a4-4b22-aaa0-e2fc72793ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_resampled_shap = pd.DataFrame(dfs_features_train_resampled_shap['Model_3_3_XGBClassifier'])\n",
    "\n",
    "features_train_shap, features_test_shap, target_train_shap, target_test_shap = train_test_split(features_resampled_shap, target_train_resampled, random_state=12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7716fe-32ed-4a4a-93a0-67e965cb543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, predictions, total_time = train_model_generate_predictions(model_3_XGBClassifier, param_grid_XGBClassifier, features_train_shap, target_train_shap, features_test_shap)\n",
    "\n",
    "calculate_metrics(grid_search, predictions, 'Si', features_test_shap, target_test_shap, total_time, 'model_3_XGBClassifier_resampled_Shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9177a50-98d2-465e-8eea-a97f9fb11144",
   "metadata": {},
   "source": [
    "***Modelo LGBMClassifier usando SHAP***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc5262-dfa8-4709-8850-2a3e1f41375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del modelo\n",
    "model_4_LGBMClassifier = LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc822aa-fd13-4f00-bf3f-eb83a7ad2444",
   "metadata": {},
   "source": [
    "Datos sin sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc3021c-cace-4dae-bb97-00c9694cdbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_shap = pd.DataFrame(dfs_features_train_shap['Model_4_LGBMClassifier'])\n",
    "\n",
    "features_train_shap, features_test_shap, target_train_shap, target_test_shap = train_test_split(features_shap, target_train, random_state=12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94570eb6-d695-4d34-b8ba-d03d4c67c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, predictions, total_time = train_model_generate_predictions(model_4_LGBMClassifier, param_grid_LGBMClassifier, features_train_shap, target_train_shap, features_test_shap)\n",
    "\n",
    "calculate_metrics(grid_search, predictions, 'No', features_test_shap, target_test_shap, total_time, 'Model_4_LGBMClassifier_shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb25cb3-2a96-4912-8094-9ca5781852be",
   "metadata": {},
   "source": [
    "Datos con sobre muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33542ff-0ab3-489b-8864-b54d8944432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_resampled_shap = pd.DataFrame(dfs_features_train_resampled_shap['Model_4_4_LGBMClassifier'])\n",
    "\n",
    "features_train_shap, features_test_shap, target_train_shap, target_test_shap = train_test_split(features_resampled_shap, target_train_resampled, random_state=12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e823e-9982-4055-8666-10663d36bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, predictions, total_time = train_model_generate_predictions(model_4_LGBMClassifier, param_grid_LGBMClassifier, features_train_shap, target_train_shap, features_test_shap)\n",
    "\n",
    "calculate_metrics(grid_search, predictions, 'Si', features_test_shap, target_test_shap, total_time, 'Model_4_LGBMClassifier_resampled_Shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c16f06-4bca-46a9-965d-8d05e8a12e15",
   "metadata": {},
   "source": [
    "Se listan los resultados entregados por los modelos entrenos con y sin sobremuestreo y con el uso de SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbc418-f763-40fa-aefb-12b6fa1ed385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta la configuración para mostrar más caracteres\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Se muestran en pantalla los resultados obtenidos por cada modelo en los diferentes escenarios generados\n",
    "df_models_results = pd.DataFrame(models_results)\n",
    "df_models_results_resampled = pd.DataFrame(models_results_resampled)\n",
    "display(df_models_results)\n",
    "display(df_models_results_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b43b9a-3212-4af4-9b0e-75c70385c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestran los resultados de los dos mejores modelos\n",
    "best_exactitud = 0\n",
    "best_model = ''\n",
    "best_auc = 0\n",
    "\n",
    "print('Datos del mejor modelo sin sobremuestreo')\n",
    "for index, row in df_models_results.iterrows():\n",
    "   if row['AUC-ROC'] >= best_auc:\n",
    "      best_auc = row['AUC-ROC']\n",
    "      if row['Precision'] >= best_exactitud:\n",
    "         best_exactitud = row['Precision']\n",
    "         best_model = row\n",
    "\n",
    "print(best_model)\n",
    "print('')            \n",
    "\n",
    "\n",
    "best_auc = 0\n",
    "best_exactitud = 0\n",
    "best_model = ''\n",
    "\n",
    "print('')\n",
    "print('Datos del mejor modelo con sobremuestreo')\n",
    "for index, row in df_models_results_resampled.iterrows():\n",
    "    if row['AUC-ROC'] >= best_auc:\n",
    "       best_auc = row['AUC-ROC']\n",
    "       if row['Precision'] >= best_exactitud:\n",
    "          best_exactitud = row['Precision']\n",
    "          best_model = row\n",
    "                    \n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2c375d-ab60-4b5a-a47a-1360c6d55834",
   "metadata": {},
   "source": [
    "***Analisis mejores modelos***\n",
    "\n",
    "Para el entrenamiento de los modelos predictivos se aplico sobre muestreo y SHAP para poder evaluar los cambios entregados en cada uno de ellos al medir las metricas objetivo.\n",
    "\n",
    "#### Datos sin sobre muestreo\n",
    "\n",
    "- El modelo que mejor desempeño presento fue el basado en ***XGBClassifier***, alcanzando el valor maximo el la metrica SP.\n",
    "\n",
    "#### Datos con sobre muestreo\n",
    "\n",
    "- El modelo que mejor desempeño presento fue el basado en ***RandomForestClassifier***, alcanzando el valor maximo el la metrica SP.\n",
    "\n",
    "Al revisar los datos entregados por cada uno de los modelos mencionados anteriormente, se sugiere trabajar con RandomForestClassifier y datos son sobre muestreo, ya que mejora las metricas de XGBClassifier y toma el mismo tiempo.\n",
    "\n",
    "\n",
    "Grafico de los resultados entregados por los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c90b5-52e6-466b-af04-b2e1fc5945f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas numéricas para escalarlas\n",
    "numeric_columns = ['Segundos', 'SP', 'AUC-ROC', 'Precision']\n",
    "\n",
    "# Escalar las métricas\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_models_results[numeric_columns]),\n",
    "    columns=numeric_columns,\n",
    "    index=df_models_results['Modelo']\n",
    ")\n",
    "\n",
    "df_resampled_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_models_results_resampled[numeric_columns]),\n",
    "    columns=numeric_columns,\n",
    "    index=df_models_results_resampled['Modelo']\n",
    ")\n",
    "\n",
    "# Crear gráfico de barras agrupadas\n",
    "x = np.arange(len(df_scaled.index))  # Posiciones en el eje x\n",
    "width = 0.35  # Ancho de las barras\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Iterar sobre cada métrica para crear las barras\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    plt.bar(\n",
    "        x - width/2 + i * width / len(numeric_columns),  # Posición ajustada de las barras\n",
    "        df_scaled[column],\n",
    "        width=width / len(numeric_columns),\n",
    "        label=f'{column} (original)',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.bar(\n",
    "        x + width/2 + i * width / len(numeric_columns),  # Posición ajustada de las barras\n",
    "        df_resampled_scaled[column],\n",
    "        width=width / len(numeric_columns),\n",
    "        label=f'{column} (resampled)',\n",
    "        alpha=0.7,\n",
    "        hatch='/'  # Añadir patrón a las barras para diferenciarlas\n",
    "    )\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "plt.title('Comparación de resultados con y sin sobremuestreo en los datos', fontsize=14)\n",
    "plt.xlabel('Modelos', fontsize=12)\n",
    "plt.ylabel('Métricas Escaladas', fontsize=12)\n",
    "plt.xticks(ticks=x, labels=df_scaled.index, rotation=45)  # Usar nombres de modelos en el eje x\n",
    "\n",
    "# Colocar la leyenda fuera del gráfico a la derecha\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1, fontsize=10)  # Ajuste fuera del gráfico\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)  # Líneas de guía solo en el eje y\n",
    "plt.tight_layout(pad=3.0)  # Aumentar el espacio alrededor de los elementos\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e43c6-25ec-418d-99ce-30c884ff56d9",
   "metadata": {},
   "source": [
    "El grafico anterior corrobora los resultados entregados por el modelo ***RandomForestClassifier*** usando datos con sobre muestreo. Se puede observar el poco tiempo que toma su entrenamuneto, generacion de resulatdos y un mayor valor en la clasifiacion SP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2649d-c2e3-4a78-b2a7-0fb7e6b92b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar frecuencias de nombres en ambos diccionarios\n",
    "counter_resampled = Counter()\n",
    "counter_original = Counter()\n",
    "\n",
    "for key, names in dfs_features_train_resampled_shap.items():\n",
    "    counter_resampled.update(names)\n",
    "\n",
    "for key, names in dfs_features_train_shap.items():\n",
    "    counter_original.update(names)\n",
    "\n",
    "# Combinar los contadores en un DataFrame\n",
    "all_names = set(counter_resampled.keys()).union(set(counter_original.keys()))\n",
    "data = {\n",
    "    \"Name\": list(all_names),\n",
    "    \"Resampled\": [counter_resampled[name] for name in all_names],\n",
    "    \"Original\": [counter_original[name] for name in all_names],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ordenar descendentemente por la suma de las frecuencias\n",
    "df[\"Total\"] = df[\"Resampled\"] + df[\"Original\"]\n",
    "df = df.sort_values(by=\"Total\", ascending=False).drop(columns=[\"Total\"])\n",
    "\n",
    "# Graficar las frecuencias\n",
    "df.set_index(\"Name\").plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Frecuencia de las columnas que superan el umbral aplicado al valor maximo dado por SHAP\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.xlabel(\"Nombre columna\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title=\"Fuente\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee541f-b438-4c2a-9f56-21184fef5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la frecuencia de todas las columnas\n",
    "all_columns = [col for columns in dfs_features_train_shap.values() for col in columns]\n",
    "column_counter = Counter(all_columns)\n",
    "\n",
    "# Ordenar de mayor a menor por frecuencia\n",
    "sorted_columns = column_counter.most_common()\n",
    "columns = [item[0] for item in sorted_columns]  # Nombres de columnas\n",
    "frequencies = [item[1] for item in sorted_columns]  # Frecuencias\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(columns, frequencies, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Nombres de Columnas', fontsize=6)\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Frecuencia de columnas en los datos sin sobre muestreo')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05e8d5-4260-4d85-ad97-938c6f1d5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la frecuencia de todas las columnas\n",
    "all_columns = [col for columns in dfs_features_train_resampled_shap.values() for col in columns]\n",
    "column_counter = Counter(all_columns)\n",
    "\n",
    "# Ordenar de mayor a menor por frecuencia\n",
    "sorted_columns_resampled = column_counter.most_common()\n",
    "columns = [item[0] for item in sorted_columns]  # Nombres de columnas\n",
    "frequencies = [item[1] for item in sorted_columns]  # Frecuencias\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(columns, frequencies, color='green', edgecolor='black')\n",
    "plt.xlabel('Nombres de Columnas', fontsize=6)\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Frecuencia de columnas en los datos con sobre muestreo')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0639d45-8664-4c7e-a05f-5c0a07f3a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Columnas que mas se repiten con SHAP sin sobremuestreo')\n",
    "\n",
    "for col, freq in counter_original.items():  # Usar .items() para iterar por pares clave-valor\n",
    "    if freq > 1:\n",
    "        print(f\"Columna: {col}, Frecuencia: {freq}\")\n",
    "\n",
    "print('')\n",
    "print('Columnas que mas se repiten con SHAP con sobremuestreo')\n",
    "for col, freq in counter_resampled.items():  # Usar .items() para iterar por pares clave-valor\n",
    "    if freq > 1:\n",
    "        print(f\"Columna: {col}, Frecuencia: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c5b25-f257-412d-908e-242204b84e0c",
   "metadata": {},
   "source": [
    "# Plan de Trabajo\n",
    "\n",
    "## 1. Definición del Problema\n",
    "\n",
    "### Objetivo: \n",
    "\n",
    "Predecir la probabilidad de cancelación que tienen los clientes.\n",
    "\n",
    "#### Métricas objetivo:\n",
    "\n",
    "##### - ***Métrica principal***: AUC-ROC (Área bajo la curva de la curva ROC).\n",
    "##### - ***Métricas adicionales***:\n",
    "    - Exactitud.\n",
    "    - log_loss.\n",
    "    \n",
    "#### Criterios de evaluación:\n",
    "\n",
    "- AUC-ROC < 0.75: 0 SP.\n",
    "- 0.75 ≤ AUC-ROC < 0.81: 4 SP.\n",
    "- 0.81 ≤ AUC-ROC < 0.85: 4.5 SP.\n",
    "- 0.85 ≤ AUC-ROC < 0.87: 5 SP.\n",
    "- 0.87 ≤ AUC-ROC < 0.88: 5.5 SP.\n",
    "- AUC-ROC ≥ 0.88: 6 SP.\n",
    "\n",
    "### 1.1 Carga de los datos\n",
    "\n",
    "- Carga de los diferentes conjuntos de datos en formato dataframe.\n",
    "  \n",
    "## 2. Entendimiento del Conjunto de Datos\n",
    "\n",
    "### Revisión inicial:\n",
    "- Analizar la columna EndDate para confirmar que los clientes con valor ***\"No\"*** están etiquetados como no cancelados.\n",
    "- Identificar el balance de clases (proporción de cancelados vs. no cancelados).\n",
    "- Revisar los tipos de datos acorde a la informacion que representan cada una de las características disponibles.\n",
    "- Analizar los rangos de valores en cada columna.\n",
    "- Analizar relevancia de las diferentes columnas en los resultados de las predicciones.\n",
    "\n",
    "***Analisis datos columna*** EndDate\n",
    "\n",
    "- ***Valores unicos***: los valores unicos no presentan inconsistencias o rangos no permitidos.\n",
    "- ***Balance de clases***:\n",
    "\n",
    "    - ***73.46%*** de los clientes tienen su contrato vigente- \n",
    "    - ***26.54%*** de los clientes han cancelado.\n",
    "    - ***Nota***: esto siguiere la posibilidad de usar sobremuestreo para balancear las clases.\n",
    "      \n",
    "#### Preguntas clave:\n",
    "\n",
    "- ***¿Qué variables parecen correlacionarse más con la cancelación?***\n",
    "\n",
    "    - Se identificaron como relevantes las siguientes columnas:\n",
    " \n",
    "        - ***df_personal***: gender, seniorcitizen\n",
    "            \n",
    "        - ***df_contract***: paymentmethod, totalcharges\n",
    "            \n",
    "        - ***df_internet***: techsupport\n",
    "            \n",
    "        - ***df_phone***: multipleLines\n",
    "            \n",
    "- ***¿Hay variables redundantes o irrelevantes que se puedan eliminar?***\n",
    "\n",
    "    - No se observan columnas con datos irrelevantes, sin embargo se deben hacer pruebas de incidencia en los resultados para poder determinar la relevancia de caracteristicas y asi depurar los datos para una mejor interpretacion por parte del modelo.\n",
    "\n",
    "## 3. Preparación de los Datos\n",
    "\n",
    "### 3.1 Limpieza de datos:\n",
    "\n",
    "- Pasar a minuscula los nombres de las columnas.\n",
    "- ***Codificacion binaria***: Tranformar columnas como partner, dependents paperlessbilling y multiplelines en valores 1 y 0.\n",
    "- Buscar registros duplicados.\n",
    "- Identificar y procesar valores ausentes.\n",
    "    ##### ***Hallazgos***\n",
    "  \n",
    "        - df_contratc\n",
    "\n",
    "            - Columna enddate: ***5174 valores ausentes*** (73.46%). Estos valores corresponden a contratos vigentes, por lo que no es necesario imputarlos.\n",
    "\n",
    "            - columna totalcharges: ***11 valores ausentes*** (0.16%) que representan el ***0.16%*** de los datos. Estos registros seran eliminados debido a su baja representatividad.\n",
    "  \n",
    "- Homogeneizar texto en columnas tipo object (minusculas, sin espacios en blanco).\n",
    "- Revisar y ajustar valores minimos, maximos y unicos en cada columna.\n",
    "- Modificar los tipos de datos segun la informacion representada.\n",
    "\n",
    "    ##### ***Analisis valores minimos, maximos y unicos***\n",
    "\n",
    "Al revisar los valores minimo y maximo de todos los conjuntos de datos, se pueden observar las siguientes novedades:\n",
    "\n",
    "- df_personal:\n",
    "  \n",
    "    - La columna seniorcitizen maneja valores de 0 y 1 con un tipo de dato object. Se pasara int para disminuir el consumo de memoria al almecenar el dato.\n",
    "      \n",
    "- df_contract:\n",
    "  \n",
    "    - La columna begindate maneja fechas con un tipo de dato object. Se pasara a tipo datetime para procesar correctamente los datos de fecha.\n",
    "    - La columna enddate maneja fechas con un tipo de dato object. Se pasara a tipo datetime para procesar correctamente los datos de fecha.\n",
    "    - La columna totalcharges maneja datos numericos con un tipo de dato objetc. Se pasara a float64 para procesar correctamente los datos.\n",
    "\n",
    "Las demas columnas tiene un tipo de dato acorde a la informacion que representan.\n",
    "\n",
    "\n",
    "Los ***valores unicos*** encontrados en las diferentes columnas estan dentro de los rangos permitidos segun la informacion de representan, sin embargo, la columna begindate del conjunto de datos df_contract representa fechas, estos datos estan estructurados como object; la columna de pasara a datetime para que las fechas se procesen adecuadamente.\n",
    "    \n",
    "- 3.2 Codificación y transformación:\n",
    " \n",
    "    - Consolidar los datos en un único registro por cliente.\n",
    "        - Revisar valores ausentes en el nuevo conjunto de datos.\n",
    "        - Crear la columna objetivo basada en enddate.\n",
    "    - Codificar variables categóricas, como métodos de pago y tipos de contrato, utilizando técnicas como One-Hot Encoding.\n",
    "    - Escalar variables numéricas.\n",
    "      \n",
    "- 3.3 Análisis exploratorio de datos (EDA):\n",
    "  \n",
    "    - Visualizar la distribución de clases (cancelados vs. no cancelados).\n",
    "\n",
    "## 4. Construcción del Modelo Predictivo\n",
    "\n",
    "### 4.1 División de datos:\n",
    "\n",
    "- Dividir los datos en entrenamiento (80%) y prueba (20%), asegurando una proporción equilibrada entre clases.\n",
    "  \n",
    "### 4.2 Selección del modelo:\n",
    "\n",
    "- Evaluar los siguientes algoritmos_\n",
    "- Regresión logística.\n",
    "- Random Forest Classifier.\n",
    "- Gradient Boosting (XGBoost, LightGBM).\n",
    "- Comparar los modelos utilizando AUC-ROC como métrica principal.\n",
    "- \n",
    "### 4.3 Evaluación del modelo:\n",
    "\n",
    "- Validación cruzada para asegurar la estabilidad.\n",
    "- Comparar modelos basandose en AUC-ROC,  exactitud y log_loss.\n",
    "  \n",
    "### 4.4 Optimización del modelo:\n",
    "\n",
    "- Ajustar hiperparámetros utilizando técnicas como Grid Search o Random Search para maximizar AUC-ROC.\n",
    "- Equilibrar clases mediante técnicas como sobremuestreo (SMOTE) o submuestreo si hay desbalance.\n",
    "\n",
    "## 5. Interpretación de Resultados\n",
    "\n",
    "### Importancia de características:\n",
    "\n",
    "- Identificar variables clave con la herramienta SHAP.\n",
    "\n",
    "        Se define un ***umbral del 5%*** del valor maximo obtenido por SHAP al aplicarlo a los modelos, obteniendo los siguiente resultados (5 columnas mas representativas):\n",
    "\n",
    "        - Regresión logística sin sobremuestreo                   Regresión logística con sobremuestreo\n",
    "\n",
    "        - type_month-to-month.                                    - monthlycharges.          \n",
    "        - monthlycharges.                                         - totalcharges.\n",
    "        - totalcharges.                                           - deviceprotection_1.\n",
    "        - mesbegindate_3.                                         - mesbegindate_4.\n",
    "        - diabegindate_3.                                         - diabegindate_4.\n",
    "  \n",
    "  \n",
    "        - Random Forest Classifier sin sobremuestreo              Random Forest Classifier con sobremuestreo\n",
    "\n",
    "        - type_month-to-month.                                    - type_month-to-month.\n",
    "        - totalcharges.                                           - yearbegindate.\n",
    "        - internetservice_fiber_optic.                            - totalcharges.\n",
    "        - yearbegindate.                                          - paymentmethod_electronic_check.\n",
    "        - type_one_year.                                          - type_two_year.\n",
    "  \n",
    "  \n",
    "        - Gradient Boosting XGBoost sin sobremuestreo             Gradient Boosting XGBoost con sobremuestreo\n",
    "\n",
    "        - totalcharges.                                           - mesbegindate_2.\n",
    "        - type_month-to-month.                                    - type_one_year.\n",
    "        - mesbegindate_1.                                         - mesbegindate_10.\n",
    "        - streamingmovies_0.                                      - mesbegindate_12.\n",
    "        - monthlycharges.                                         - paymentmethod_bank_transfer_(automatic).\n",
    "  \n",
    "  \n",
    "        - Gradient Boosting LightGBM sin sobremuestreo            Gradient Boosting LightGBM sin sobremuestreo\n",
    "\n",
    "        - totalcharges.                                           - mesbegindate_12.\n",
    "        - type_month-to-month.                                    - mesbegindate_2.\n",
    "        - streamingmovies_0.                                      - mesbegindate_10.\n",
    "        - onlinebackup_0.                                         - paymentmethod_bank_transfer_(automatic).\n",
    "        - dependents_0.                                           - paperlessbilling_1.\n",
    "\n",
    "En el analisis de las columnas en los diferentes modelos entrenados con datos sin y con sobremuestreo, en primer lugar se observa la presencia de la columna ***totalcharges*** y en segundo lugar esta la columna ***type_month-to-month***. Las demas columnas no tienen un patron tan marcado como las dos mencionadas anteriormente. \n",
    "Con la presencia de las columnas ***totalcharges*** y ***type_month-to-month*** como las mas representativas en las predicciones de las posibilidades de que el cliente cancele el contrato, se pueden realizar estudios de comportamiento con respecto al cargo total que paga el cliente y el tipo de contrato que tiene, para con base en los resultados, poder implementar estrategias comerciales que lleven a una mayor permanencia de los clientes con sus respectivos contratos.\n",
    "\n",
    "### Resultados esperados:\n",
    ".\n",
    "- AUC-ROC >= 0.81 para para obtener al menos 4.5 SP.\n",
    "\n",
    "Acontinuacion se listan los diferentes resultados entregados por cada modelo:\n",
    "\n",
    "***Resultados sin sobremuestreo***\n",
    "\n",
    "| Modelo                      | Segundos | SP   | AUC-ROC | Precision | log_loss | Sobremuestreo |\n",
    "|-----------------------------|----------|------|---------|-----------|----------|---------------|\n",
    "| LogisticRegression          | 67.49    | 4.5  | 0.85    | 0.80      | 0.42     | No            |\n",
    "| RandomForestClassifier      | 14.66    | 5.0  | 0.87    | 0.82      | 0.40     | No            |\n",
    "| XGBClassifier               | 22.56    | 6.0  | 0.91    | 0.86      | 0.32     | No            |\n",
    "| LGBMClassifier              | 73.04    | 6.0  | 0.90    | 0.81      | 0.38     | No            |\n",
    "| LogisticRegression_Shap     | 2.23     | 4.5  | 0.82    | 0.80      | 0.45     | No            |\n",
    "| RandomForestClassifier_shap | 10.87    | 5.5  | 0.87    | 0.83      | 0.38     | No            |\n",
    "| XGBClassifier_shap          | 5.46     | 4.0  | 0.80    | 0.78      | 0.45     | No            |\n",
    "| LGBMClassifier_shap         | 9.24     | 4.0  | 0.78    | 0.77      | 0.47     | No            |\n",
    "\n",
    "***Resultados con sobremuestreo***\n",
    "\n",
    "| Modelo                               | Segundos | SP   | AUC-ROC | Precision | log_loss | Sobremuestreo |\n",
    "|--------------------------------------|----------|------|---------|-----------|----------|---------------|\n",
    "| LogisticRegression_resampled         | 2.43     | 4.5  | 0.85    | 0.76      | 0.48     | Sí            |\n",
    "| RandomForestClassifier_resampled     | 18.80    | 5.0  | 0.86    | 0.82      | 0.45     | Sí            |\n",
    "| XGBClassifier_resampled              | 56.98    | 6.0  | 0.86    | 0.86      | 0.34     | Sí            |\n",
    "| LGBMClassifier_resampled             | 31.30    | 6.0  | 0.84    | 0.84      | 0.36     | Sí            |\n",
    "| LogisticRegression_resampled_Shap    | 0.37     | 4.0  | 0.81    | 0.72      | 0.54     | Sí            |\n",
    "| RandomForestClassifier_resampled_Shap| 13.35    | 6.0  | 0.94    | 0.86      | 0.34     | Sí            |\n",
    "| XGBClassifier_resampled_Shap         | 6.69     | 4.0  | 0.68    | 0.68      | 0.54     | Sí            |\n",
    "| LGBMClassifier_resampled_Shap        | 11.29    | 4.0  | 0.69    | 0.69      | 0.58     | Sí            |\n",
    "\n",
    "***Comparacion de resultados con y sin sobremuestreo***\n",
    "\n",
    "| Modelo                                   | Segundos | SP    | AUC-ROC | Precision | log_loss | Sobremuestreo |\n",
    "|------------------------------------------|----------|-------|---------|-----------|----------|---------------|\n",
    "| LogisticRegression (original vs resampled)         | 65.06   | 0.0   | 0.00    | 0.04      | -0.06    | No vs Sí     |\n",
    "| RandomForestClassifier (original vs resampled) | -4.14 | 0.0 | 0.01 | 0.00 | -0.05 | No vs Sí |\n",
    "| **XGBClassifier (original vs resampled)**              | **-34.42**  | **0.0**   | **0.05**    | **0.00**      | **-0.02**    | **No vs Sí**     |\n",
    "| LGBMClassifier (original vs resampled)             | 41.74   | 0.0   | 0.06    | -0.03     | 0.02     | No vs Sí     |\n",
    "| LogisticRegression_Shap (original vs resampled)    | 1.86    | 0.5   | 0.01    | 0.08      | -0.09    | No vs Sí     |\n",
    "| **RandomForestClassifier_Shap (original vs resampled)** | **-2.48** | **-0.5** | **-0.07** | **-0.03** | **0.04** | **No vs Sí** |\n",
    "| XGBClassifier_Shap (original vs resampled)         | -1.23   | 0.0   | 0.12    | 0.10      | -0.09    | No vs Sí     |\n",
    "| LGBMClassifier_Shap (original vs resampled)        | -2.05   | 0.0   | 0.09    | 0.08      | -0.11    | No vs Sí     |\n",
    "\n",
    "En la anterior tabla se resaltan los modelos con mejores resultados. \n",
    "\n",
    "***Sin sobremuestreo***:\n",
    "   - El modelo basado en el algoritmo ***XGBClassifier*** entrego los mejores resultados al balancear de mejor forma los valores generados para cada una de las metricas que se usaron como parametro para determinar la calidad de las predicciones. La siguiente es la seleccion de hiperparametros usados en el modelo: ***'colsample_bytree': 1.0, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 40***\n",
    "\n",
    "***Con sobremuestreo***:\n",
    "   - El modelo basado en el algoritmo ***RandomForestClassifier*** entrego los mejores resultados al balancear de mejor forma los valores generados para cada una de las metricas que se usaron como parametro para determinar la calidad de las predicciones. En este entrenamiento se realizo ***sobremuestreo*** y aplico ***SHAP*** para seleccionar las columnas con mayor participacion en la generacion de predicciones. La siguiente es la seleccion de hiperparametros usados en el modelo: ***'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 40***\n",
    "\n",
    "## 6. Reporte y Presentación\n",
    "\n",
    "### 6.1 ***Portada***\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <strong><em>Título del proyecto</em></strong>: Posibilidad de cancelación del contrato por parte del cliente.<br>\n",
    "    <strong><em>Presentado por</em></strong>: Jose Luis Fernandez R.<br>\n",
    "    <strong><em>Fecha</em></strong>: Diciembre 13 de 2024.\n",
    "</div>\n",
    "\n",
    "### 6.2 Introducción\n",
    "\n",
    "- Objetivo general del proyecto: Predecir la probabilidad de cancelación que tienen los clientes.\n",
    "  \n",
    "- Problema a resolver y su importancia: Se han detectado cancelaciones frecuentes de contratos por parte de los clientes sin una razon aparente, como resultado situacion afecta de manera directa los ingresos de la empresa y dificulta la posibilidad de mejorar los servicios al desconocer sus puntos debiles en la prestacion de sus servicios.\n",
    "Breve descripción de los datos utilizados: Para la ejecucion de este proyecto se utilizo la informacion de los clientes registrada en la empresa asi como el listado de los diferentes servicios que se ofrecen. \n",
    "\n",
    "### 6.3 Metodología\n",
    "\n",
    "#### 6.3.1 Descripción del proceso\n",
    "\n",
    "- Definición del problema: Se desconocen las causas por las cuales los clientes realizan la cancelacion de sus contratos.\n",
    "  \n",
    "- Preparación y limpieza de datos: La informacion entregada para le realizacion del proyecto se unifico en un solo conjunto de datos para el procesamiento de valores ausentes y determinar como manejarlos, tambien poder suprimir caracteres que no fueran parte de los datos, analizar los rangos y valores unicos dentro de cada una de las columnas y homogeneizar el uso de minusculas.\n",
    "  \n",
    "- Exploración de los datos: En este paso se analizaron los balances de las clases, es decir, en que medida en el conjunto de datos aparece con mayor frecuencia en dato que indica la cancelacion del contrato. Posteriormente para pasar a la eleccion y entrenamiento de modelos, se separaron los conjuntos de datos dando el 80% del total para el entrenamiento y el 20% restante para pruebas de validacion.\n",
    "  \n",
    "#### 6.3.2 Selección de modelos\n",
    "\n",
    "- **Métodos y algoritmos considerados:**\n",
    "  \n",
    "    - **Modelos supervisados:** Debido a la naturaleza del problema (predecir la probabilidad de cancelación de contratos), se utilizaron modelos supervisados.\n",
    "      \n",
    "    - **Modelos de clasificación:** Los principales algoritmos considerados fueron modelos de clasificación binaria, ya que el objetivo es predecir una variable categórica: si un cliente cancelará o no su contrato.\n",
    "      \n",
    "    - **Modelos más utilizados en problemas similares:**\n",
    "      \n",
    "        - **Regresión logística:** Modelo sencillo y eficiente para estimar probabilidades de eventos binarios.\n",
    "      \n",
    "        - **Árboles de decisión y Random Forest:** Estos modelos permiten identificar características no lineales en los datos y son sencillos de interpretar.\n",
    "\n",
    "        - **XGBoost:** Un modelo basado en gradiente boosting que ha demostrado un excelente desempeño en tareas de clasificación.\n",
    "\n",
    "        - **LightGBM:** Similar a XGBoost, es una variante más eficiente que maneja bien grandes volúmenes de datos y es capaz de capturar patrones complejos de forma rápida.\n",
    "\n",
    "- **Técnicas de procesamiento:**\n",
    "\n",
    "    - **Over-sampling (sobremuestreo):** En el conjunto de datos entregado existe una mayor presencia de clientes que no han cancelado su contrato, lo que lleva a un desbalance en las clases. Por este motivo, se utilizó el método SMOTE para generar registros con datos de cancelación de contrato y analizar los resultados con este nuevo escenario.\n",
    "\n",
    "    - **Codificación de variables categóricas:** Las columnas de tipo objeto se codificaron utilizando ***OneHotEncoder***.\n",
    "\n",
    "    - **Escalado de variables:** Las columnas de tipo numérico se escalaron utilizando ***StandardScaler***.\n",
    "      \n",
    "    - **Busqueda de hiperparametros:** Para poder seleccionar el mejor modelo y su configuracion se utilizo ***GridSearchCV*** con validacion cruzada, de esta manera de optimizo el uso del conjunto de datos en la generacion de posibles configuraciones para los diferentes modelos.\n",
    "\n",
    "- **Justificación de la elección de los modelos:**\n",
    "\n",
    "    - **Características del problema:**\n",
    "\n",
    "        - ***Predicción binaria:*** El modelo debe ser capaz de clasificar correctamente a los clientes que cancelan su contrato frente a los que no lo hacen. Por lo tanto, los modelos seleccionados se centraron en la clasificación binaria.\n",
    "\n",
    "        - ***Interpretabilidad:*** Los modelos como regresión logística y árboles de decisión son fácilmente interpretables, lo cual es relevante para entender los factores clave que influyen en la cancelación de contratos. Este es un valor agregado, ya que los resultados no solo deben ser precisos, sino también explicables para que los responsables de la toma de decisiones puedan actuar sobre ellos.\n",
    "\n",
    "        - ***Manejo de datos desbalanceados:*** Se debe contemplar la posible desproporción entre clientes que cancelan o no su contrato. Los modelos como ***Random Forest***, ***XGBoost*** y ***LightGBM*** pueden manejar el desbalance mediante técnicas como pesos ajustados en las clases o sampling.\n",
    "\n",
    "    - **Rendimiento esperado:**\n",
    "\n",
    "        - Modelos como ***XGBoost*** y ***LightGBM*** han mostrado excelente desempeño en problemas similares, por lo que fueron elegidos para evaluar su rendimiento en el caso de la cancelación de contratos.\n",
    "\n",
    "        - ***Random Forest*** y ***Árboles de Decisión*** fueron tenidos en cuenta para obtener un modelo robusto con buena capacidad de generalización, ya que son menos propensos al sobreajuste en comparación con algunos otros modelos.\n",
    "\n",
    "    - **Complejidad computacional:**\n",
    "\n",
    "        - ***XGBoost*** y ***LightGBM*** ofrecen una ventaja en términos de eficiencia computacional. Al manejar grandes volúmenes de datos y entrenarse rápidamente, se priorizan estos modelos para garantizar que los experimentos se lleven a cabo en un tiempo razonable.\n",
    "\n",
    "        - Modelos como la ***regresión logística*** fueron considerados como una base para comparar la efectividad de los modelos más complejos, ya que, aunque no son tan potentes, ofrecen un desempeño decente en muchos escenarios y tienen un bajo costo computacional.\n",
    "\n",
    "#### 6.3.3 Criterios de evaluación:\n",
    "\n",
    "- **Métricas utilizadas:**\n",
    "  \n",
    "  El modelo seleccionado debía obtener una clasificación mínima de ***4.5 SP***. Esta es una métrica proporcionada por la empresa que evalúa el nivel de exactitud del modelo basado en su desempeño en la ***Curva AUC-ROC***. Para ser considerado, el modelo debía alcanzar un valor mínimo de 0.81 en la AUC-ROC. Además, se incluyeron métricas complementarias como ***precisión (accuracy)*** y ***log-loss***, con el propósito de ofrecer una visión más completa del rendimiento del modelo.\n",
    "\n",
    "- **Relevancia de las métricas:**\n",
    "\n",
    "  - ***SP (Scoring Performance):***  \n",
    "    Esta valoración, proporcionada por la empresa, se asigna al modelo con base en los siguientes parámetros:  \n",
    "    \n",
    "      - **AUC-ROC < 0.75:** 0 SP.  \n",
    "      - **0.75 ≤ AUC-ROC < 0.81:** 4 SP.  \n",
    "      - **0.81 ≤ AUC-ROC < 0.85:** 4.5 SP.  \n",
    "      - **0.85 ≤ AUC-ROC < 0.87:** 5 SP.  \n",
    "      - **0.87 ≤ AUC-ROC < 0.88:** 5.5 SP.  \n",
    "      - **AUC-ROC ≥ 0.88:** 6 SP.\n",
    "\n",
    "  - ***Curva AUC-ROC (Área Bajo la Curva - Receiver Operating Characteristic):***  \n",
    "    Esta métrica mide la capacidad del modelo para diferenciar entre clases. Es especialmente relevante en este caso porque permite evaluar cuán bien el modelo identifica a los clientes propensos a cancelar su contrato. Un valor cercano a 1 indica un alto desempeño.\n",
    "\n",
    "  - ***Precisión (accuracy):***  \n",
    "    Representa el porcentaje de predicciones correctas del modelo en relación con el total de datos evaluados. Aunque es una métrica útil, debe interpretarse junto con otras métricas, especialmente en problemas con clases desbalanceadas. Un valor cercano a 1 refleja un modelo con errores mínimos.\n",
    "\n",
    "  - ***Log-loss (Pérdida Logarítmica):***  \n",
    "    Evalúa la calidad de las predicciones probabilísticas del modelo, centrándose en qué tan bien predice la probabilidad de la clase positiva. En este caso, la clase positiva corresponde a clientes propensos a cancelar su contrato, por lo que esta métrica es clave para medir el desempeño del modelo. Un valor cercano a 0 indica un modelo con alta probabilidad de prediccion correcta en la clase positiva.\n",
    "\n",
    "- **Notas adicionales:**  \n",
    "  Las métricas se eligieron cuidadosamente para ofrecer un balance entre la interpretabilidad de los resultados y su relevancia para el problema de negocio. Esto asegura que los responsables de la toma de decisiones puedan entender y utilizar los resultados del modelo de manera efectiva.\n",
    "\n",
    "#### 6.3.4 Técnicas adicionales:\n",
    "\n",
    "- En la preparación de los datos se utilizó **sobremuestreo (SMOTE)** y **análisis de relevancia en las predicciones para cada columna (SHAP)**.\n",
    "\n",
    "  - **SMOTE (Synthetic Minority Over-sampling Technique):**  \n",
    "    Con esta técnica se buscó otorgar balance a las clases y así evitar que los modelos aprendieran de manera desproporcionada sobre una clase en particular. El balance se logra mediante la generación de datos sintéticos, basados en los registros originales, para adicionar datos con el mismo comportamiento que la clase minoritaria.\n",
    "\n",
    "  - **SHAP (SHapley Additive exPlanations):**  \n",
    "    Esta técnica es fundamental para entender cuáles variables son determinantes en la cancelación de contratos. SHAP asigna un valor de importancia a cada variable en función de su contribución a las predicciones del modelo. Estos valores se calculan utilizando la teoría de juegos, específicamente el concepto de los valores de Shapley, que distribuyen de manera justa la importancia entre todas las variables que contribuyen al resultado.\n",
    "\n",
    "    - **Generación de valores SHAP:**  \n",
    "      Para cada predicción, SHAP descompone el impacto de cada variable, comparando cómo cambia la predicción del modelo al incluir o excluir una variable. Este análisis se realiza para todas las filas del conjunto de datos, generando una distribución de valores SHAP para cada variable. La importancia general de una variable se calcula como la media absoluta de sus valores SHAP en todo el conjunto de datos.\n",
    "\n",
    "    - **Interpretación de los valores:**  \n",
    "      Un valor SHAP alto (positivo o negativo) indica que una variable tuvo un impacto significativo en la predicción del modelo, mientras que un valor cercano a cero sugiere que la variable tuvo poco o ningún impacto. Este análisis permite identificar variables clave para estrategias de marketing o comerciales que contrarresten la pérdida de clientes.\n",
    "\n",
    "### Notas adicionales:\n",
    "1. **SHAP y explicabilidad:** Los valores SHAP no solo ayudan a entender el modelo, sino también a generar confianza en su uso al explicar sus decisiones de manera transparente.\n",
    "\n",
    "### 6.4 Resultados\n",
    "\n",
    "#### Comparación entre modelos\n",
    "\n",
    "Se realizó el siguiente entrenamiento con los cuatro modelos seleccionados:\n",
    "\n",
    "- **Datos originales:** Registros sin ninguna técnica adicional de procesamiento.\n",
    "- **Datos con sobremuestreo:** Registros con un mayor número de filas que balancean la cantidad de veces que aparece cada una de las clases.\n",
    "- **Datos originales con SHAP:** Registros sin sobremuestreo y con las columnas que superan el umbral (5%) de importancia definido según el valor máximo otorgado a las columnas por el método SHAP.\n",
    "- **Datos con sobremuestreo y SHAP:** Registros con sobremuestreo y con las columnas que superan el umbral (5%) de importancia definido según el valor máximo otorgado a las columnas por el método SHAP.\n",
    "\n",
    "Utilizando estos cuatro escenarios para el entrenamiento de cada modelo, se obtuvieron los siguientes resultados:\n",
    "\n",
    "| Modelo                                         | Segundos | SP    | AUC-ROC | Precision | log_loss | Sobremuestreo |\n",
    "|------------------------------------------------|----------|-------|---------|-----------|----------|---------------|\n",
    "| LogisticRegression (original vs resampled)    | 65.06    | 0.0   | 0.00    | 0.04      | -0.06    | No vs Sí      |\n",
    "| RandomForestClassifier (original vs resampled)| -4.14    | 0.0   | 0.01    | 0.00      | -0.05    | No vs Sí      |\n",
    "| **XGBClassifier (original vs resampled)**      | **-34.42**| **0.0**| **0.05**| **0.00**  | **-0.02**| **No vs Sí**  |\n",
    "| LGBMClassifier (original vs resampled)         | 41.74    | 0.0   | 0.06    | -0.03     | 0.02     | No vs Sí      |\n",
    "| LogisticRegression_SHAP (original vs resampled)| 1.86     | 0.5   | 0.01    | 0.08      | -0.09    | No vs Sí      |\n",
    "| **RandomForestClassifier_SHAP (original vs resampled)** | **-2.48** | **-0.5**| **-0.07** | **-0.03** | **0.04** | **No vs Sí** |\n",
    "| XGBClassifier_SHAP (original vs resampled)    | -1.23    | 0.0   | 0.12    | 0.10      | -0.09    | No vs Sí      |\n",
    "| LGBMClassifier_SHAP (original vs resampled)   | -2.05    | 0.0   | 0.09    | 0.08      | -0.11    | No vs Sí      |\n",
    "\n",
    "#### Análisis de resultados\n",
    "\n",
    "Tras analizar los valores generados por los modelos para cada una de las métricas evaluadas, se observa que los dos modelos con mejores resultados son **XGBClassifier** y **RandomForestClassifier**. La tabla muestra la diferencia de los valores generados con y sin sobremuestreo; los valores más altos (positivos o negativos) indican qué modelo realiza mejores predicciones.\n",
    "\n",
    "Adicionalmente, se identificaron las siguientes observaciones:\n",
    "\n",
    "- **Impacto del uso de SHAP:**  \n",
    "  Los modelos ***XGBClassifier*** y ***LGBMClassifier*** son afectados negativamente por el uso de SHAP, ya que esta técnica reduce el conjunto de características y, por ende, el volumen de los datos. Esto impide que los modelos puedan aprender de manera óptima.\n",
    "\n",
    "- **Rendimiento de RandomForestClassifier:**  \n",
    "  Por el contrario, al modelo **RandomForestClassifier** le beneficia el uso combinado de SHAP y el sobremuestreo. El balance de clases que aporta el sobremuestreo evita el sesgo hacia alguna clase, mientras que la limpieza de características proporcionada por SHAP permite al modelo aprender de forma más eficiente.\n",
    "\n",
    "En conclusión, el uso estratégico de técnicas como SHAP y el sobremuestreo puede mejorar significativamente el rendimiento de algunos modelos. Sin embargo, su impacto varía según el modelo utilizado, siendo especialmente favorable para RandomForestClassifier debido a su capacidad inherente para manejar datos complejos y equilibrados.\n",
    "\n",
    "### 6.5 Discusión\n",
    "\n",
    "Tras analizar los datos correspondientes a cada una de las métricas utilizadas para evaluar los resultados del modelo, e interpretar los resultados obtenidos con el modelo elegido (**RandomForestClassifier**), se llegó a las siguientes conclusiones:\n",
    "\n",
    "1. **Análisis de columnas clave:**  \n",
    "   Un análisis detallado de las columnas ***totalcharges*** y ***type_month-to-month*** revela que estas variables tienen un impacto significativo en la permanencia de los clientes. Esto sugiere que focalizar estrategias en estas áreas podría mejorar el promedio de permanencia.\n",
    "\n",
    "2. **Entrenamiento periódico del modelo:**  \n",
    "   Es importante resaltar que el modelo debe ser entrenado periódicamente con datos actualizados. Este enfoque permitirá identificar si han surgido cambios en el comportamiento de cancelación de contratos por parte de los clientes, asegurando así que las predicciones del modelo se mantengan relevantes y precisas.\n",
    "\n",
    "En resumen, el uso del modelo **RandomForestClassifier** junto con un monitoreo constante de las variables más influyentes puede servir como una herramienta eficaz para predecir y mejorar la retención de clientes.\n",
    "\n",
    "### 6.6 Conclusión y Recomendaciones\n",
    "\n",
    "Como conclusiones del proyecto, se destacan los siguientes puntos:\n",
    "\n",
    "1. **Estructura de los datos:**  \n",
    "   Los datos originales cuentan con una estructura adecuada para los valores que representan. Sin embargo, para evitar complicaciones en el procesamiento de ciertas columnas y garantizar una mayor fidelidad, se sugieren las siguientes mejoras en el almacenamiento de los registros:  \n",
    "   - Las columnas de tipo fecha podrían desglosarse en tres columnas separadas que representen el día, mes y año respectivamente.  \n",
    "   - Las columnas que almacenan valores booleanos (\"yes\" y \"no\") podrían transformarse en valores numéricos, asignando 1 para \"yes\" y 0 para \"no\".\n",
    "\n",
    "2. **Próximos entrenamientos del modelo:**  \n",
    "   Para futuros entrenamientos del modelo elegido, se recomienda ajustar los valores de los hiperparámetros **n_estimators** y **max_depth**. Este ajuste permitirá manejar eficientemente un mayor volumen de datos que podría generarse a partir de las próximas ventas, optimizando así el rendimiento del modelo.\n",
    "\n",
    "3. **Ventajas del modelo:**  \n",
    "   El modelo **RandomForestClassifier** no solo ofrece un excelente balance entre las métricas evaluadas, sino que también presenta un bajo costo computacional. Esto lo convierte en una opción altamente competitiva y fácil de implementar. La combinación de alta precisión y tiempos de ejecución reducidos representa una ventaja estratégica para la empresa, al contar con una herramienta eficiente y confiable.\n",
    "\n",
    "---\n",
    "\n",
    "En resumen, implementar estas recomendaciones permitirá optimizar tanto el manejo de los datos como el rendimiento del modelo, generando un impacto positivo en la toma de decisiones empresariales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
